{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1OSXPb2LCkxCMDKlmyXN5xmxalfPG_wve","timestamp":1730551924434},{"file_id":"1B7GsZxMv2rRB3ae5R0Xb6AbQmGMEwD0z","timestamp":1730391100949}],"gpuType":"A100","machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"8edd0fb816114b07af44cd6131e911d0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5de102c38fe141aeabdb30edd07bb50e","IPY_MODEL_cfd197d7bc454e0099485d806b3c4b60","IPY_MODEL_4bc7fe54d98a4bac9a49c3709729ec4a"],"layout":"IPY_MODEL_4e703bb3653d43769c5ff66fbac2c2c7"}},"5de102c38fe141aeabdb30edd07bb50e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b2d9bfa50adb4d48b9ca781d67634d04","placeholder":"​","style":"IPY_MODEL_5081c52a4c7c448eb72c686bf94a0460","value":"Loading checkpoint shards: 100%"}},"cfd197d7bc454e0099485d806b3c4b60":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7cfcd9f5158a42df850a9455fec42ed9","max":4,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5e36c1f21bdb48318be03a7ceab24953","value":4}},"4bc7fe54d98a4bac9a49c3709729ec4a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_02a6c287170d4b418972a9017ffd12ac","placeholder":"​","style":"IPY_MODEL_1cda07d28f074132a7c5787f5aff6397","value":" 4/4 [00:07&lt;00:00,  1.65s/it]"}},"4e703bb3653d43769c5ff66fbac2c2c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2d9bfa50adb4d48b9ca781d67634d04":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5081c52a4c7c448eb72c686bf94a0460":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7cfcd9f5158a42df850a9455fec42ed9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e36c1f21bdb48318be03a7ceab24953":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"02a6c287170d4b418972a9017ffd12ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1cda07d28f074132a7c5787f5aff6397":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d502384275c44013894d52841373a77b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_df67f24c3a9d4bea82d36a1888ba47b3","IPY_MODEL_e58da92ff96d4ee78e5f8e609ca14caf","IPY_MODEL_28e0f42597ba47a6ba4bbbe3cbd546eb"],"layout":"IPY_MODEL_f5466c80e4dc405b85ac4179690d47d2"}},"df67f24c3a9d4bea82d36a1888ba47b3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8453491542804fdb8bee25caca77b8b2","placeholder":"​","style":"IPY_MODEL_fe5ddb391d804389b866889deb7b77fc","value":"Map (num_proc=4): 100%"}},"e58da92ff96d4ee78e5f8e609ca14caf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_848e43d0ec5b4383bf050c086bd6e321","max":10240,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e6631100521f49ab829d3464be9fa745","value":10240}},"28e0f42597ba47a6ba4bbbe3cbd546eb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_20389b112a2d4132b0f2c51ff5508201","placeholder":"​","style":"IPY_MODEL_289647a021894a7dbfaeb79e82b753ed","value":" 10240/10240 [00:00&lt;00:00, 28265.77 examples/s]"}},"f5466c80e4dc405b85ac4179690d47d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8453491542804fdb8bee25caca77b8b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe5ddb391d804389b866889deb7b77fc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"848e43d0ec5b4383bf050c086bd6e321":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6631100521f49ab829d3464be9fa745":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"20389b112a2d4132b0f2c51ff5508201":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"289647a021894a7dbfaeb79e82b753ed":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1421c2d0a3a74cd1a9b9b7e2ab7a5f3a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_556b05f1ce3e4de5a3b816bd279dc1c3","IPY_MODEL_fb9a37bcaeee49c0b6d1070ae6d27dd2","IPY_MODEL_2eee1b871dd64dffb32959907450ad11"],"layout":"IPY_MODEL_f34cfe95f3314880a97e91258f4f767b"}},"556b05f1ce3e4de5a3b816bd279dc1c3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fe418b487c5d475c862f7789b7bedbb8","placeholder":"​","style":"IPY_MODEL_ce103984d5ab44fea737e82259e88991","value":"Map (num_proc=4): 100%"}},"fb9a37bcaeee49c0b6d1070ae6d27dd2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_acd4dfc744ae423dbbe3f99eff9a01a8","max":2560,"min":0,"orientation":"horizontal","style":"IPY_MODEL_45ae0f9275174bf78b084475b1f1a400","value":2560}},"2eee1b871dd64dffb32959907450ad11":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f9efff2a3884856a7444edd4ec21e67","placeholder":"​","style":"IPY_MODEL_fd3fbbe027824419b491568118d248de","value":" 2560/2560 [00:00&lt;00:00, 3097.33 examples/s]"}},"f34cfe95f3314880a97e91258f4f767b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe418b487c5d475c862f7789b7bedbb8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce103984d5ab44fea737e82259e88991":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"acd4dfc744ae423dbbe3f99eff9a01a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45ae0f9275174bf78b084475b1f1a400":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8f9efff2a3884856a7444edd4ec21e67":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd3fbbe027824419b491568118d248de":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a229d990f9dc4f0f86ec81a40543f671":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f8000c19d2724b80b84cce7fd0fce43c","IPY_MODEL_47e6312cfa624311b8b89f0558f7360c","IPY_MODEL_c194e2f6cde042ffadeaa42d3e6be881"],"layout":"IPY_MODEL_6df548f3f8194bb8be5362d16b5009f4"}},"f8000c19d2724b80b84cce7fd0fce43c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d8946b14e70a4bed93b8c821099cb2da","placeholder":"​","style":"IPY_MODEL_4b157e000c534486a7adbdeb0b44c1bc","value":"Map (num_proc=4): 100%"}},"47e6312cfa624311b8b89f0558f7360c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c355a5ce39644ff38d3505c1b1b3de93","max":10240,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e9468bd86cce4bd7b0e26b980779ce4b","value":10240}},"c194e2f6cde042ffadeaa42d3e6be881":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f340fa4675ad4d59bf5089d2d46ed7dc","placeholder":"​","style":"IPY_MODEL_a0c5547f71f441cb8b4f078e35fb569e","value":" 10240/10240 [00:04&lt;00:00, 3450.28 examples/s]"}},"6df548f3f8194bb8be5362d16b5009f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d8946b14e70a4bed93b8c821099cb2da":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b157e000c534486a7adbdeb0b44c1bc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c355a5ce39644ff38d3505c1b1b3de93":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e9468bd86cce4bd7b0e26b980779ce4b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f340fa4675ad4d59bf5089d2d46ed7dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a0c5547f71f441cb8b4f078e35fb569e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9924dbd6d95549e4ab83e6a4c7948173":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_57abab8317584ebeac65cb9fe8788bc9","IPY_MODEL_42254a9e8c6e4f08b1e7711517ef5838","IPY_MODEL_e5f8486b23644da386b069ddcb8e7b9e"],"layout":"IPY_MODEL_0403a0513dce444291a12e1dbe56deee"}},"57abab8317584ebeac65cb9fe8788bc9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_76bf7d40ea7543e4b4b75c6e53cf9871","placeholder":"​","style":"IPY_MODEL_c18709838bc34062bc621dcaadfa27fa","value":"Loading checkpoint shards: 100%"}},"42254a9e8c6e4f08b1e7711517ef5838":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_58e5d914a4dd492cb43dfbbf50cc3eb7","max":4,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1c3c43ff287a42bcb8d47b5d73b47fcc","value":4}},"e5f8486b23644da386b069ddcb8e7b9e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_96c81791bc7247149af19fac1841c78e","placeholder":"​","style":"IPY_MODEL_561d3c1665914c6a9ed6538199da111f","value":" 4/4 [00:06&lt;00:00,  1.47s/it]"}},"0403a0513dce444291a12e1dbe56deee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"76bf7d40ea7543e4b4b75c6e53cf9871":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c18709838bc34062bc621dcaadfa27fa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"58e5d914a4dd492cb43dfbbf50cc3eb7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c3c43ff287a42bcb8d47b5d73b47fcc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"96c81791bc7247149af19fac1841c78e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"561d3c1665914c6a9ed6538199da111f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# Math Question Answer Verification Competition\n","\n","## Starter Code"],"metadata":{"id":"70hrNJwhYMjR"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9h8g9YJNNKYH","executionInfo":{"status":"ok","timestamp":1731697757356,"user_tz":300,"elapsed":30207,"user":{"displayName":"DeepLearning","userId":"07574442120191513945"}},"outputId":"178acaa9-e3bf-4454-f5cd-33e3c5a5a5c6"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["Borrowed from [official Unsloth implementation](https://colab.research.google.com/drive/1Ys44kVvmeZtnICzWz0xgpRnrIOjZAuxp?usp=sharing#scrollTo=MKX_XKs_BNZR)"],"metadata":{"id":"kp8dK32_gOZu"}},{"cell_type":"code","source":["# Code Description\n","# this code is used to train model which was trained on base model with learning rate 1e-4 and 32000 samples\n","# instead of loading original lora model it loads trained lora model from previous step\n","# generate another 32000 random banlanced samples split with 80% train and 20% validation\n","# and continue traing the model with learning rate 1e-4\n"],"metadata":{"id":"THWn8f0oAQr-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # %%capture\n","# # This cell will take time\n","!pip install unsloth\n","# # Also get the latest nightly Unsloth!\n","!pip uninstall unsloth -y && pip install --upgrade --no-cache-dir \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\""],"metadata":{"id":"bA1lW9pzWwpk","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"84846635-e75f-41bc-bebc-0043135e881f","executionInfo":{"status":"ok","timestamp":1731697933439,"user_tz":300,"elapsed":176086,"user":{"displayName":"DeepLearning","userId":"07574442120191513945"}}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting unsloth\n","  Downloading unsloth-2024.11.7-py3-none-any.whl.metadata (59 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/59.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting unsloth-zoo>=2024.11.1 (from unsloth)\n","  Downloading unsloth_zoo-2024.11.5-py3-none-any.whl.metadata (16 kB)\n","Requirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (2.5.0+cu121)\n","Collecting xformers>=0.0.27.post2 (from unsloth)\n","  Downloading xformers-0.0.28.post3-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n","Collecting bitsandbytes (from unsloth)\n","  Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n","Collecting triton>=3.0.0 (from unsloth)\n","  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from unsloth) (24.2)\n","Collecting tyro (from unsloth)\n","  Downloading tyro-0.8.14-py3-none-any.whl.metadata (8.4 kB)\n","Requirement already satisfied: transformers>=4.46.1 in /usr/local/lib/python3.10/dist-packages (from unsloth) (4.46.2)\n","Collecting datasets>=2.16.0 (from unsloth)\n","  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.2.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unsloth) (4.66.6)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unsloth) (5.9.5)\n","Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.44.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from unsloth) (1.26.4)\n","Requirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.10/dist-packages (from unsloth) (1.1.1)\n","Collecting trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9 (from unsloth)\n","  Downloading trl-0.12.1-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.13.2)\n","Collecting protobuf<4.0.0 (from unsloth)\n","  Downloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (679 bytes)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.26.2)\n","Collecting hf-transfer (from unsloth)\n","  Downloading hf_transfer-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.1->unsloth) (6.0.2)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.1->unsloth) (0.4.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (3.16.1)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (17.0.0)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.16.0->unsloth)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (2.32.3)\n","Collecting xxhash (from datasets>=2.16.0->unsloth)\n","  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess<0.70.17 (from datasets>=2.16.0->unsloth)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n","Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=2.16.0->unsloth)\n","  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (3.10.10)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->unsloth) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (3.1.4)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.4.0->unsloth) (1.3.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.46.1->unsloth) (2024.9.11)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.46.1->unsloth) (0.20.3)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (13.9.4)\n","Collecting torch>=2.4.0 (from unsloth)\n","  Downloading torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.4.0->unsloth)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.4.0->unsloth)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.4.0->unsloth)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.4.0->unsloth)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.4.0->unsloth)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.4.0->unsloth)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-nccl-cu12==2.21.5 (from torch>=2.4.0->unsloth)\n","  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-nvtx-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n","  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth) (0.16)\n","Collecting shtab>=1.5.6 (from tyro->unsloth)\n","  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.17.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (4.0.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (2024.8.30)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (2.18.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.4.0->unsloth) (3.0.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth) (2024.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (0.1.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth) (1.16.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets>=2.16.0->unsloth) (0.2.0)\n","Downloading unsloth-2024.11.7-py3-none-any.whl (163 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.9/163.9 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading datasets-3.1.0-py3-none-any.whl (480 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading trl-0.12.1-py3-none-any.whl (310 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.9/310.9 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading unsloth_zoo-2024.11.5-py3-none-any.whl (31 kB)\n","Downloading xformers-0.0.28.post3-cp310-cp310-manylinux_2_28_x86_64.whl (16.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.7/16.7 MB\u001b[0m \u001b[31m97.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl (906.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.4/906.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m103.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m88.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl (122.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading hf_transfer-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tyro-0.8.14-py3-none-any.whl (109 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.8/109.8 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\n","Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: xxhash, triton, shtab, protobuf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, hf-transfer, fsspec, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, tyro, nvidia-cusolver-cu12, torch, xformers, datasets, bitsandbytes, trl, unsloth-zoo, unsloth\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 4.25.5\n","    Uninstalling protobuf-4.25.5:\n","      Successfully uninstalled protobuf-4.25.5\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.6.77\n","    Uninstalling nvidia-nvjitlink-cu12-12.6.77:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.77\n","  Attempting uninstall: nvidia-nccl-cu12\n","    Found existing installation: nvidia-nccl-cu12 2.23.4\n","    Uninstalling nvidia-nccl-cu12-2.23.4:\n","      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.7.77\n","    Uninstalling nvidia-curand-cu12-10.3.7.77:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n","    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n","      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n","    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n","    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.6.3.3\n","    Uninstalling nvidia-cublas-cu12-12.6.3.3:\n","      Successfully uninstalled nvidia-cublas-cu12-12.6.3.3\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2024.10.0\n","    Uninstalling fsspec-2024.10.0:\n","      Successfully uninstalled fsspec-2024.10.0\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n","    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.5.1.17\n","    Uninstalling nvidia-cudnn-cu12-9.5.1.17:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.5.1.17\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n","    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.5.0+cu121\n","    Uninstalling torch-2.5.0+cu121:\n","      Successfully uninstalled torch-2.5.0+cu121\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\n","grpcio-status 1.62.3 requires protobuf>=4.21.6, but you have protobuf 3.20.3 which is incompatible.\n","torchaudio 2.5.0+cu121 requires torch==2.5.0, but you have torch 2.5.1 which is incompatible.\n","torchvision 0.20.0+cu121 requires torch==2.5.0, but you have torch 2.5.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed bitsandbytes-0.44.1 datasets-3.1.0 dill-0.3.8 fsspec-2024.9.0 hf-transfer-0.1.8 multiprocess-0.70.16 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 protobuf-3.20.3 shtab-1.7.1 torch-2.5.1 triton-3.1.0 trl-0.12.1 tyro-0.8.14 unsloth-2024.11.7 unsloth-zoo-2024.11.5 xformers-0.0.28.post3 xxhash-3.5.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["google"]},"id":"e40f4f0933904d47bf0677760c12affa"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Found existing installation: unsloth 2024.11.7\n","Uninstalling unsloth-2024.11.7:\n","  Successfully uninstalled unsloth-2024.11.7\n","Collecting unsloth@ git+https://github.com/unslothai/unsloth.git (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-install-gcv4e6hq/unsloth_195ced1ff3b6441fa6c3208015fc3623\n","  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-install-gcv4e6hq/unsloth_195ced1ff3b6441fa6c3208015fc3623\n","  Resolved https://github.com/unslothai/unsloth.git to commit f26d4e739ed507de7a9088da53d10fd02f58d160\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: unsloth-zoo>=2024.11.1 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.11.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (24.2)\n","Requirement already satisfied: tyro in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.8.14)\n","Requirement already satisfied: transformers>=4.46.1 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.46.2)\n","Requirement already satisfied: datasets>=2.16.0 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.1.0)\n","Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.2.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.66.6)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (5.9.5)\n","Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.44.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.26.4)\n","Requirement already satisfied: protobuf<4.0.0 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.20.3)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.26.2)\n","Requirement already satisfied: hf-transfer in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.8)\n","Requirement already satisfied: bitsandbytes>=0.43.3 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.44.1)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.5.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.16.1)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (17.0.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.32.3)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.5.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.70.16)\n","Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.9.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.10.10)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.0.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.12.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.46.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.9.11)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.46.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.4.5)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.46.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.20.3)\n","Requirement already satisfied: triton in /usr/local/lib/python3.10/dist-packages (from unsloth-zoo>=2024.11.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.1.0)\n","Requirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.10/dist-packages (from unsloth-zoo>=2024.11.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.1.1)\n","Requirement already satisfied: trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9 in /usr/local/lib/python3.10/dist-packages (from unsloth-zoo>=2024.11.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.12.1)\n","Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from unsloth-zoo>=2024.11.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.13.2)\n","Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.16)\n","Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (13.9.4)\n","Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.7.1)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.17.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.0.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.8.30)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.18.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.1.4)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.3.1.170)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.4.127)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.16.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.2.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.2)\n","Building wheels for collected packages: unsloth\n","  Building wheel for unsloth (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for unsloth: filename=unsloth-2024.11.7-py3-none-any.whl size=163138 sha256=f6eab1f88c2728454d4def7a9e4c449ae460bb316aa10b7acee0d928dd923cdf\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-9movpi2_/wheels/ed/d4/e9/76fb290ee3df0a5fc21ce5c2c788e29e9607a2353d8342fd0d\n","Successfully built unsloth\n","Installing collected packages: unsloth\n","Successfully installed unsloth-2024.11.7\n"]}]},{"cell_type":"code","source":["max_seq_length = 1024 # Choose any\n","dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n","load_in_4bit = False # Use 4bit quantization to reduce memory usage. Can be False.\n","max_steps=200 # 1000*16*4=64000 datapoints"],"metadata":{"id":"zlpjJOhtW7g3","executionInfo":{"status":"ok","timestamp":1731698573550,"user_tz":300,"elapsed":290,"user":{"displayName":"DeepLearning","userId":"07574442120191513945"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["from unsloth import FastLanguageModel\n","import torch\n","\n","# 加载Meta-Llama-3.1-8B预训练模型\n","model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name = \"/content/drive/MyDrive/0.842\",\n","    max_seq_length = max_seq_length,\n","    dtype = dtype,\n","    load_in_4bit = load_in_4bit,\n",")"],"metadata":{"id":"5GxOyBTkXJIG","colab":{"base_uri":"https://localhost:8080/","height":176,"referenced_widgets":["8edd0fb816114b07af44cd6131e911d0","5de102c38fe141aeabdb30edd07bb50e","cfd197d7bc454e0099485d806b3c4b60","4bc7fe54d98a4bac9a49c3709729ec4a","4e703bb3653d43769c5ff66fbac2c2c7","b2d9bfa50adb4d48b9ca781d67634d04","5081c52a4c7c448eb72c686bf94a0460","7cfcd9f5158a42df850a9455fec42ed9","5e36c1f21bdb48318be03a7ceab24953","02a6c287170d4b418972a9017ffd12ac","1cda07d28f074132a7c5787f5aff6397"]},"executionInfo":{"status":"ok","timestamp":1731698591534,"user_tz":300,"elapsed":16942,"user":{"displayName":"DeepLearning","userId":"07574442120191513945"}},"outputId":"8171ad1e-85eb-42eb-a72b-49d4a5399d60"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["==((====))==  Unsloth 2024.11.7: Fast Llama patching. Transformers = 4.46.2.\n","   \\\\   /|    GPU: NVIDIA A100-SXM4-40GB. Max memory: 39.564 GB. Platform = Linux.\n","O^O/ \\_/ \\    Pytorch: 2.5.1+cu124. CUDA = 8.0. CUDA Toolkit = 12.4.\n","\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post3. FA2 = False]\n"," \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"]},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8edd0fb816114b07af44cd6131e911d0"}},"metadata":{}}]},{"cell_type":"markdown","source":["## Load model and wrap with LoRA adapters"],"metadata":{"id":"jVgabGjM8G1r"}},{"cell_type":"code","source":["model = FastLanguageModel.get_peft_model(\n","    model,\n","    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n","    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n","                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n","    lora_alpha = 16,\n","    lora_dropout = 0, # Supports any, but = 0 is optimized\n","    bias = \"none\",    # Supports any, but = \"none\" is optimized\n","    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n","    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n","    random_state = 3407,\n","    use_rslora = False,  # We support rank stabilized LoRA\n","    loftq_config = None, # And LoftQ\n",")"],"metadata":{"id":"xy0iN0RJXMAX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1731698591534,"user_tz":300,"elapsed":5,"user":{"displayName":"DeepLearning","userId":"07574442120191513945"}},"outputId":"5f495d53-a600-4e3d-b244-772877d5e813"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stderr","text":["Unsloth: Already have LoRA adapters! We shall skip this step.\n"]}]},{"cell_type":"markdown","source":["## Competition dataset"],"metadata":{"id":"uNruHjDieGSS"}},{"cell_type":"code","source":["# download and load competition dataset\n","import numpy as np\n","torch.manual_seed(3000)\n","np.random.seed(3000)\n","from datasets import load_dataset\n","full_dataset = load_dataset(\"ad6398/nyu-dl-teach-maths-comp\")\n","dataset = full_dataset['train'].shuffle(seed=3000)"],"metadata":{"id":"3OMXJz4Z8jhJ","executionInfo":{"status":"ok","timestamp":1731698594723,"user_tz":300,"elapsed":3191,"user":{"displayName":"DeepLearning","userId":"07574442120191513945"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["prompt = \"\"\"You are a great mathematician and you are tasked with finding if an answer to a given maths question is correct or not.\n","Follow these steps to verify if the given answer is correct.\n","\n","### [Step 1] Task Description\n","Carefully read the question to understand the type of mathematical problem.\n","Question:\n","{}\n","\n","### [Step 2]Check the given answer\n","Examine the provided answer below to determine if it is mathematically equivalent to the computed solution.\n","Given Answer:\n","{}\n","\n","### [Step 3] Verify and solve step by step\n","- Check if all given information is used correctly\n","- Verify calculations and mathematical operations\n","Step-by-step verification:\n","{}\n","\n","###[Step 4] After completing the verification steps, respond ONLY with \"True\" if correct, or \"False\" if it is not.\n","Output:\n","{}\"\"\"\n","\n","EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n","def formatting_prompts_func(examples):\n","    question = examples[\"question\"]\n","    ans       = examples[\"answer\"]\n","    solution  = examples[\"solution\"]\n","    output      = examples[\"is_correct\"]\n","    texts = []\n","    for instruction, input,solution, output in zip(question, ans,solution, output):\n","        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n","        # text = prompt.format(instruction, input, output) + EOS_TOKEN\n","        text = prompt.format(instruction, input, solution, output) + EOS_TOKEN\n","        texts.append(text)\n","    return { \"text\" : texts, }"],"metadata":{"id":"DBpDwJA-bJ9K","executionInfo":{"status":"ok","timestamp":1731698594723,"user_tz":300,"elapsed":4,"user":{"displayName":"DeepLearning","userId":"07574442120191513945"}}},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":["## Create Balanced Dataset with train and validation\n"],"metadata":{"id":"bi_sMTuTGUnq"}},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from datasets import Dataset, concatenate_datasets\n","from collections import Counter\n","\n","def create_balanced_training_subset(dataset, max_steps, batch_size, grad_accum_steps, train_ratio=0.8):\n","    \"\"\"\n","    Create balanced training and validation datasets with 80-20 split.\n","    Ensures both splits maintain class balance.\n","\n","    Args:\n","        dataset: Input dataset\n","        max_steps: Maximum training steps\n","        batch_size: Batch size for training\n","        grad_accum_steps: Gradient accumulation steps\n","        train_ratio: Ratio of training set (default: 0.8 or 80%)\n","    \"\"\"\n","    # Calculate total samples needed for training from max_steps\n","    total_samples = max_steps * batch_size * grad_accum_steps  # 1000 * 16 * 4 = 64000\n","\n","    # Calculate total samples needed (train + validation)\n","    train_samples = int(total_samples * train_ratio)  # 64000 * 0.8 =\n","    val_samples = total_samples - train_samples\n","\n","    # Calculate samples per class for each split to maintain balance\n","    train_samples_per_class = train_samples // 2  # 25600 // 2 = 12800\n","    val_samples_per_class = val_samples // 2  # 6400 // 2 = 3200\n","\n","    # Separate True and False samples from original dataset\n","    true_samples = dataset.filter(lambda x: x['is_correct'] == True)\n","    false_samples = dataset.filter(lambda x: x['is_correct'] == False)\n","\n","    print(f\"\\nCreating balanced datasets:\")\n","    print(f\"Training samples per class: {train_samples_per_class:,}\")\n","    print(f\"Validation samples per class: {val_samples_per_class:,}\")\n","\n","    # Sample indices for training and validation for each class\n","    true_indices = np.random.permutation(len(true_samples))\n","    false_indices = np.random.permutation(len(false_samples))\n","\n","    # Split indices for training and validation\n","    true_train_indices = true_indices[:train_samples_per_class]\n","    true_val_indices = true_indices[train_samples_per_class:train_samples_per_class + val_samples_per_class]\n","    false_train_indices = false_indices[:train_samples_per_class]\n","    false_val_indices = false_indices[train_samples_per_class:train_samples_per_class + val_samples_per_class]\n","\n","    # Create training dataset\n","    train_true = true_samples.select(true_train_indices)\n","    train_false = false_samples.select(false_train_indices)\n","    train_dataset = concatenate_datasets([train_true, train_false])\n","    train_dataset = train_dataset.shuffle(seed=42)\n","\n","    # Create validation dataset\n","    val_true = true_samples.select(true_val_indices)\n","    val_false = false_samples.select(false_val_indices)\n","    val_dataset = concatenate_datasets([val_true, val_false])\n","    val_dataset = val_dataset.shuffle(seed=42)\n","\n","    # Print statistics\n","    print(\"\\nOriginal dataset statistics:\")\n","    original_counts = Counter(dataset['is_correct'])\n","    print(f\"True: {original_counts[True]:,} ({original_counts[True]/len(dataset)*100:.1f}%)\")\n","    print(f\"False: {original_counts[False]:,} ({original_counts[False]/len(dataset)*100:.1f}%)\")\n","\n","    print(\"\\nTraining dataset statistics:\")\n","    train_counts = Counter(train_dataset['is_correct'])\n","    print(f\"Total samples: {len(train_dataset):,}\")\n","    print(f\"True: {train_counts[True]:,} ({train_counts[True]/len(train_dataset)*100:.1f}%)\")\n","    print(f\"False: {train_counts[False]:,} ({train_counts[False]/len(train_dataset)*100:.1f}%)\")\n","\n","    print(\"\\nValidation dataset statistics:\")\n","    val_counts = Counter(val_dataset['is_correct'])\n","    print(f\"Total samples: {len(val_dataset):,}\")\n","    print(f\"True: {val_counts[True]:,} ({val_counts[True]/len(val_dataset)*100:.1f}%)\")\n","    print(f\"False: {val_counts[False]:,} ({val_counts[False]/len(val_dataset)*100:.1f}%)\")\n","\n","    # Visualize distributions\n","    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 5))\n","\n","    # Original distribution\n","    orig_counts = [original_counts[True], original_counts[False]]\n","    ax1.bar(['True', 'False'], orig_counts)\n","    ax1.set_title('Original Dataset Distribution')\n","    for i, count in enumerate(orig_counts):\n","        ax1.text(i, count, f'{count:,}\\n({count/len(dataset)*100:.1f}%)',\n","                ha='center', va='bottom')\n","\n","    # Training distribution\n","    train_count_vals = [train_counts[True], train_counts[False]]\n","    ax2.bar(['True', 'False'], train_count_vals)\n","    ax2.set_title('Training Dataset Distribution (80%)')\n","    for i, count in enumerate(train_count_vals):\n","        ax2.text(i, count, f'{count:,}\\n({count/len(train_dataset)*100:.1f}%)',\n","                ha='center', va='bottom')\n","\n","    # Validation distribution\n","    val_count_vals = [val_counts[True], val_counts[False]]\n","    ax3.bar(['True', 'False'], val_count_vals)\n","    ax3.set_title('Validation Dataset Distribution (20%)')\n","    for i, count in enumerate(val_count_vals):\n","        ax3.text(i, count, f'{count:,}\\n({count/len(val_dataset)*100:.1f}%)',\n","                ha='center', va='bottom')\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","    return train_dataset, val_dataset\n","print(max_steps)"],"metadata":{"id":"PTfJAdTPNM_X","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1731698594723,"user_tz":300,"elapsed":4,"user":{"displayName":"DeepLearning","userId":"07574442120191513945"}},"outputId":"6ddd53b5-2512-47af-b93b-278f82b00970"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["200\n"]}]},{"cell_type":"code","source":["# Create balanced train and validation datasets\n","train_dataset, val_dataset = create_balanced_training_subset(\n","    dataset=dataset,\n","    max_steps=max_steps,  # e.g., 500\n","    batch_size=16,\n","    grad_accum_steps=4\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":510},"id":"WHpi0N8PG1ix","executionInfo":{"status":"ok","timestamp":1731698601259,"user_tz":300,"elapsed":6539,"user":{"displayName":"DeepLearning","userId":"07574442120191513945"}},"outputId":"97da2048-f2e5-487f-9d30-1daf47d9279c"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Creating balanced datasets:\n","Training samples per class: 5,120\n","Validation samples per class: 1,280\n","\n","Original dataset statistics:\n","True: 400,000 (40.0%)\n","False: 600,000 (60.0%)\n","\n","Training dataset statistics:\n","Total samples: 10,240\n","True: 5,120 (50.0%)\n","False: 5,120 (50.0%)\n","\n","Validation dataset statistics:\n","Total samples: 2,560\n","True: 1,280 (50.0%)\n","False: 1,280 (50.0%)\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1800x500 with 3 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAABv4AAAHqCAYAAADMEzkrAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAClL0lEQVR4nOzde3yP9f/H8ecOdmA+mzlsFmYOYc6mWCEhiyWVDrSkkDDKIUpJDomUkGNKqBzCtyPCkPOchhxzCNFhW9E2NDu+f3902/XzsYPNYWMe99vtc6vP+/263tf7uvbxvt6f6/W5rsvBGGMEAAAAAAAAAAAA4JbmWNAdAAAAAAAAAAAAAHDtSPwBAAAAAAAAAAAAhQCJPwAAAAAAAAAAAKAQIPEHAAAAAAAAAAAAFAIk/gAAAAAAAAAAAIBCgMQfAAAAAAAAAAAAUAiQ+AMAAAAAAAAAAAAKARJ/AAAAAAAAAAAAQCFA4g8AAAAAAAAAAAAoBEj8Abeo4cOHy8HB4aqWnTNnjhwcHHTy5Mnr26lLnDx5Ug4ODpozZ84NWwcyc3Bw0PDhw2/4etatWycHBwetW7fOKmvevLlq1ap1w9ct8fkCgMLoueeeU8WKFa9q2WuZF+HmkR9z1AyXf94y5hbvv//+DV+3VPCf2dOnT8vNzU2bN28usD5cyZkzZ1SsWDEtX768oLsCADdMVt9t83KMuBHnAJo3b67mzZtf1zaR/zg/lH/atm2rF154ocDWnxuvvfaaGjVqVNDdQD4i8QfkswMHDuiZZ57RHXfcIVdXV/n5+SksLEwHDhwo6K4ViIwJQsbL1dVVPj4+at68ud555x399ddfV932wYMHNXz48Hw5eZQb8+fP18SJE3MdX7FiRWu/ODo6ysvLS7Vr11aPHj20bdu2AutXfrqZ+wYAt4tLj9M5vS79sn87ee655+z2g4eHhypVqqTHH39c//vf/5Senn7Vbd9Mx8F///1Xw4cPz/Xf+UbO8a6lX/npZu7byJEj1ahRI91777125atXr9b999+vUqVKycvLS3fffbc+//zzLNuYNWuWatSoITc3N1WtWlWTJ0/OFLN582Y1aNBAxYsXV/PmzfXzzz9ninnppZcUEhKSqbxkyZLq3r273nzzzavcSgC4vh5++GEVLVpU586dyzYmLCxMLi4uOnPmTD72LO9utvMlEueHcsL5oZu3b5s3b9aqVav06quvWmU///yzBg8erHr16ql48eIqW7asQkNDtXPnzizb+P333/Xkk0/Ky8tLNptN7du31/Hjx+1ikpKS1LdvX5UuXVrlypXT22+/namd3377TR4eHln+sKtfv3766aef9N13313jFuOWYQDkm//973/GxcXF+Pr6mjfeeMN88sknZujQoaZs2bLGxcXFfPXVV7luKyUlxSQmJl5VP1JTU01iYqJJT0+/quVz48SJE0aSmT17do5xP/74o5FkXnrpJfP555+bOXPmmPfee888+uijxtnZ2ZQsWdKsWbPmqvqwePFiI8n8+OOPV7X89RYaGmr8/f1zHe/v72/q1atnPv/8c/P555+badOmmb59+xpfX18jyfTv3z/TMomJiSYlJeWG9ssYY9LS0kxiYqJJS0uzyu677z5Ts2bNPLVztX1LT083iYmJJjU19bquDwCQWcZxKOP1wAMPGEmZyqOjo69pPcnJyebixYtXtey1zIuuVZcuXYyrq6u1H2bOnGneeOMNU6dOHSPJNG/e3MTHx19V21dzjL5R/vrrLyPJvPXWW7mKv5o53tXMUfParwyXf94y5q7vvfdentq52r4V5Gc2NjbWFClSxMyfP9+u/NtvvzUODg7mnnvuMZMnTzZTpkwxzZo1M5LMBx98YBc7Y8YMI8l06NDBzJw503Tu3NlIMmPHjrVi4uLiTMmSJU1oaKiZPn26adSokQkMDLSbv+3fv9+4ubmZAwcOZNnXgwcPGklX/X0AAK6nhQsXGklm7ty5WdZfuHDBFCtWzLRr1y7XbWZ17iQvx4irOQYak/P5kqSkJJOUlJTnNq8V54eyx/mhm/f8UPv27U3r1q3tygYOHGi8vLxMt27dzEcffWTGjRtnKleubJycnExERIRd7Llz50zVqlVNmTJlzLvvvms++OADU758eVOuXDnz999/W3GjRo0yNpvNvPvuu2bo0KFZzuU6duxoOnXqlG1fn3zySdO0adPrsNW4FTjnZ5IRuJ398ssv6ty5sypVqqQNGzaodOnSVt3LL7+spk2bqnPnztq7d68qVaqUbTsXLlxQsWLF5OzsLGfnq/sn7OTkJCcnp6ta9kZp2rSpHn/8cbuyn376Sa1bt1aHDh108OBBlS1btoB6V3DuuOMOPfPMM3Zl7777rp5++mlNmDBBVatWVa9evaw6Nze3G9qfixcvysXFRY6Ojjd8XTlxcHAo0PUDwO3k8uPQ1q1bFRERkan8cv/++6+KFi2a6/UUKVLkqvon6ZrmRdeDs7Nzpv3x9ttva+zYsRoyZIheeOEFffnllwXUu4KVlzlefsxRM+bS1/J5ux4K8jP7xRdfyNnZWe3atbMrnzJlisqWLau1a9fK1dVVkvTiiy+qevXqmjNnjvr37y9JSkxM1BtvvKHQ0FAtWbJEkvTCCy8oPT1do0aNUo8ePVSiRAlFRkYqMTFRS5YskZubmx588EEFBATo2LFjqlatmqT/fn3+wgsvKDAwMMu+1qhRQ7Vq1dKcOXPUokWLG7VLACBXHn74YRUvXlzz58/Xs88+m6n+22+/1YULFxQWFnZN6ynoeY2Li0uBrVvi/FB2OD+UtYI8PxQbG6tly5ZpxowZduWdOnXS8OHD5eHhYZV17dpVNWrU0PDhw9WqVSurfNq0aTp69Ki2b9+uu+66S5LUpk0b1apVS+PHj9c777wjSVq6dKkGDhyowYMHS/rvtu3fffedOnXqJEnatGmTvv/++yzvrpDhySef1BNPPKHjx4/neO4ZhQO3+gTyyXvvvad///1XM2fOtEv6SVKpUqX00Ucf6cKFCxo3bpxVnnFf94MHD+rpp59WiRIl1KRJE7u6SyUmJuqll15SqVKlVLx4cT388MP6/fffM93XO6vnp1SsWFEPPfSQNm3apLvvvltubm6qVKmSPvvsM7t1nD17Vq+88opq164tDw8P2Ww2tWnTRj/99NN12lP/r27dupo4caLi4uI0ZcoUq/zXX39V7969Va1aNbm7u6tkyZJ64okn7LZnzpw5euKJJyRJ999/f6bbkH377bcKDQ2Vn5+fXF1dVblyZY0aNUppaWl2fTh69Kg6dOggX19fubm5qVy5curYsaPi4+Pt4r744gsFBQXJ3d1d3t7e6tixo06fPm3VN2/eXMuWLdOvv/5q9eVqn2Pk7u6uzz//XN7e3ho9erSMMVbd5X/rc+fOqV+/fqpYsaJcXV1VpkwZPfDAA9q1a9cV+5Vxm42FCxdq6NChuuOOO1S0aFElJCRkeQ/3DFFRUbrnnnvk7u6ugICATBOg7J7fc3mbOfUtu3u4r127Vk2bNlWxYsXk5eWl9u3b69ChQ3YxGf92jh07pueee05eXl7y9PTU888/r3///Td3fwQAgJ2M53hERUWpWbNmKlq0qF5//XVJuT/m5vTMtZkzZ6py5cpydXXVXXfdpR07dtgtm9W8yMHBQX369NE333yjWrVqydXVVTVr1tSKFSsy9X/dunVq2LCh3NzcVLlyZX300UfX5Rlsr732mlq3bq3FixfryJEjVnlu9klOx8Hk5GQNGzZMQUFB8vT0VLFixdS0aVP9+OOPmfqwcOFCBQUFqXjx4rLZbKpdu7YmTZpkFxMXF6d+/fqpfPnycnV1VZUqVfTuu+9atyk9efKkNX8dMWKE1Z+rfW5MdnO8rOYIO3fuVEhIiEqVKmXNLbp27Zqrfj333HPy8PDQL7/8orZt26p48eLWydicnik5YcIE+fv7y93dXffdd5/2799vV5/ds48ubfNKfcvq85WamqpRo0ZZn/WKFSvq9ddfV1JSkl1cbuft2fnmm2/UqFEju5NRkpSQkKASJUpYST/pv5PPGfs+w48//qgzZ86od+/edsuHh4frwoULWrZsmaT/vpu4ublZJ+O8vb0lyZpvffPNN9q9e7dGjBiRY38feOABff/993ZzXgAoCO7u7nrssce0Zs0axcbGZqqfP3++dS7mWs6dZHWMSEpKUv/+/VW6dGlrHb/99lumZa/H+ZKsjnOxsbHq1q2bfHx85Obmprp162ru3Ll2MXmZu+UV54eyxvmhgj0/tGzZMqWmptol8iQpKCgo0zyrZMmSatq0aaY+LFmyRHfddZeV9JOk6tWrq2XLllq0aJFVlpiYqBIlSljvvb29rT6mp6fr5Zdf1uDBg1WuXLls+5vRz2+//faK24ZbH1f8Afnk+++/V8WKFdW0adMs65s1a6aKFStaX5Qv9cQTT6hq1ap65513cvzC+9xzz2nRokXq3LmzGjdurPXr1ys0NDTXfTx27Jgef/xxdevWTV26dNGnn36q5557TkFBQapZs6Yk6fjx4/rmm2/0xBNPKCAgQDExMfroo49033336eDBg/Lz88v1+nIjoz+rVq3S6NGjJUk7duzQli1b1LFjR5UrV04nT57U9OnT1bx5cx08eFBFixZVs2bN9NJLL+nDDz/U66+/rho1akiS9d85c+bIw8NDAwYMkIeHh9auXathw4YpISFB7733nqT/TqqFhIRY99H29fXV77//rqVLlyouLk6enp6SpNGjR+vNN9/Uk08+qe7du+uvv/7S5MmT1axZM+3evVteXl564403FB8fr99++00TJkyQpEyTgLzw8PDQo48+qlmzZungwYPW3+dyPXv21JIlS9SnTx8FBgbqzJkz2rRpkw4dOqQGDRrkql+jRo2Si4uLXnnlFSUlJeX4679//vlHbdu21ZNPPqlOnTpp0aJF6tWrl1xcXKyTdLmV1322evVqtWnTRpUqVdLw4cOVmJioyZMn695779WuXbsyTaSffPJJBQQEaMyYMdq1a5c++eQTlSlTRu+++26e+gkA+M+ZM2fUpk0bdezYUc8884x8fHwk5e6Ym5P58+fr3LlzevHFF+Xg4KBx48bpscce0/Hjx6941damTZv01VdfqXfv3ipevLg+/PBDdejQQadOnVLJkiUlSbt379aDDz6osmXLasSIEUpLS9PIkSMz/VDranXu3FmrVq1SRESE7rzzTkm52yc5HQcTEhL0ySefqFOnTnrhhRd07tw5zZo1SyEhIdq+fbvq1asnSYqIiFCnTp3UsmVL6/h26NAhbd68WS+//LKk/5Iw9913n37//Xe9+OKLqlChgrZs2aIhQ4bozz//1MSJE1W6dGlNnz5dvXr10qOPPqrHHntMklSnTp2r3i9ZzfEuFxsbq9atW6t06dJ67bXX5OXlpZMnT+qrr76SpFz1KzU1VSEhIWrSpInef//9K16F+tlnn+ncuXMKDw/XxYsXNWnSJLVo0UL79u2zPtO5cTX7rHv37po7d64ef/xxDRw4UNu2bdOYMWN06NAhff3113axuZm3ZyUlJUU7duywuyIgQ/PmzfXuu+/qzTffVJcuXeTg4KD58+dr586ddieedu/eLUlq2LCh3fJBQUFydHTU7t279cwzz6h+/fqKj4/X+PHj9fjjj2vixIny9PRUtWrVlJSUpIEDB2rEiBF2J7GyEhQUpAkTJujAgQOqVatWjrEAcKOFhYVp7ty5WrRokfr06WOVnz17VitXrlSnTp3k7u6uAwcOXNdzJ927d9cXX3yhp59+Wvfcc4/Wrl2b5fme63G+5HKJiYlq3ry5jh07pj59+iggIECLFy/Wc889p7i4OGtOkeFa5m454fxQ1jg/lFl+nR/asmWLSpYsKX9//1xtR3R0tEqVKmW9T09P1969e7PcH3fffbdWrVqlc+fOqXjx4rrrrrs0c+ZMNW/eXOfPn9eCBQusMWjWrFn6+++/NWjQoBzX7+npqcqVK2vz5s3WnRxQiBXsnUaB20NcXJyRZNq3b59j3MMPP2wkmYSEBGOMMW+99ZaRlOX9mTPqMkRFRRlJpl+/fnZxzz33XKZ7vs+ePdtIMidOnLDK/P39jSSzYcMGqyw2Nta4urqagQMHWmUXL160u2+3Mf/dk97V1dWMHDnSrkx5eMbf4sWLs42pW7euKVGihPX+33//zRQTGRlpJJnPPvvMKsvpHu5ZtfHiiy+aokWLWs972b179xX7dvLkSePk5GRGjx5tV75v3z7j7OxsV34193APDQ3Ntn7ChAlGkvn222+tssv/1p6eniY8PDzH9WTXr4y/TaVKlTLtr4y6S/ftfffdZySZ8ePHW2VJSUmmXr16pkyZMiY5OdkYk/XnL7s2s+tbVp+vjPWcOXPGKvvpp5+Mo6OjefbZZ62yjH87Xbt2tWvz0UcfNSVLlsy0LgCAvfDwcHP514iMY8CMGTMyxefmmGvMf8/Ku3TMzxjrS5Ysac6ePWuVf/vtt0aS+f77762yy+dFxvx3THRxcTHHjh2zyn766ScjyUyePNkqa9eunSlatKj5/fffrbKjR48aZ2fnTG1mpUuXLqZYsWLZ1mfMJy599kpu90l2x8HU1NRMz975559/jI+Pj93x7eWXXzY2my3HZ56MGjXKFCtWzBw5csSu/LXXXjNOTk7m1KlTxpirf8ZfXuZ4l88Rvv76ayPJ7NixI9s2cupXly5djCTz2muvZVmX1efN3d3d/Pbbb1b5tm3bMv397rvvPnPfffddsc2c+nb5Z3bPnj1Gkunevbtd3CuvvGIkmbVr11pluZ23Z+XYsWOZ/g1kOH/+vHnyySeNg4ODkWQkmaJFi5pvvvnGLi48PNw4OTll2X7p0qVNx44drffvvfeecXJysvZtxrNoRo8ebWrVqpWr5/Fs2bLFSDJffvnlFWMB4EZLTU01ZcuWNcHBwXblGc8+XblypTHm2s6dZHeM6N27t117Tz/9dKbjzPU4X3L5cW7ixIlGkvniiy+ssuTkZBMcHGw8PDysc1h5mbtlhfND2eP80M15fqhJkyYmKCjoinHGGLNhwwbj4OBg3nzzTassY6546ZiQYerUqUaS+fnnn40xxpw+fdrUrFnTmqM1bdrUnDt3zsTFxZnSpUubhQsX5qofrVu3NjVq1MhVLG5t3OoTyAfnzp2TJBUvXjzHuIz6hIQEu/KePXtecR0Zt626/JY7ffv2zXU/AwMD7a5ILF26tKpVq6bjx49bZa6urnJ0/G/oSEtL05kzZ+Th4aFq1apZtwe43jw8PKx9KMnuVkMpKSk6c+aMqlSpIi8vr1z34dI2zp07p7///ltNmzbVv//+a90PO+MXWytXrsz2Ev+vvvpK6enpevLJJ/X3339bL19fX1WtWjXLW25dLxm/brp031zOy8tL27Zt0x9//HHV6+nSpYvd/sqJs7OzXnzxReu9i4uLXnzxRcXGxioqKuqq+3Alf/75p/bs2aPnnnvOuo2U9N+v6h944AEtX7480zKX/7tq2rSpzpw5k+nfHwAgd1xdXfX8889nKs/NMTcnTz31lN0VQRlzlUvnJ9lp1aqVKleubL2vU6eObDabtWxaWppWr16tRx55xO6X91WqVFGbNm2u2H5uZHW8vtZ94uTkZP3COj09XWfPnlVqaqoaNmxoNxfy8vLShQsXFBERkW1bixcvVtOmTVWiRAm7uUyrVq2UlpamDRs25Hmbc+vyOd7lvLy8JP33TJOUlJSrXk9WV7dl55FHHtEdd9xhvb/77rvVqFGjLOcS11NG+wMGDLArHzhwoCRluitIbubtWTlz5owkZXmVnaurq+688049/vjjWrBggb744gs1bNhQzzzzjLZu3WrFJSYmZvsLfzc3NyUmJlrvX3nlFf3++++KjIzU77//rk6dOumPP/7QmDFjNHHiRKWmpqpv376qUKGC7r77bm3evDlTmxl9/fvvv3PcNgDID05OTurYsaMiIyPtbk84f/58+fj4qGXLlpKu77mTjGPESy+9ZFfer1+/TLHX43xJVuv39fW1niUm/fds5pdeeknnz5/X+vXr7eKvZe52JZwfyhrnh/5ffp4fOnPmzBXvXCD9dxeLp59+WgEBAdYz+iRZc6ZLb7OeIeNW6Rkx5cqV0+7du7V7924dOHBA69atk4eHh0aMGKFq1arpqaee0qZNm9SoUSOVL19eL730kpKTkzO1mzHnR+FH4g/IBxkJvZwOwJfWX54gDAgIuOI6fv31Vzk6OmaKrVKlSq77WaFChUxlJUqU0D///GO9T09Ptx4a7OrqqlKlSql06dLau3dvpvuaXy/nz5+32yeJiYkaNmyY9RyajD7ExcXlug8HDhzQo48+Kk9PT9lsNpUuXdp6SHJGGwEBARowYIA++eQTlSpVSiEhIZo6dardOo4ePSpjjKpWrarSpUvbvQ4dOpTlff+vl/Pnz0vKOaE8btw47d+/X+XLl9fdd9+t4cOH53mynZvPXwY/Pz8VK1bMrizjtmaX37P9evr1118lSdWqVctUV6NGDf3999+6cOGCXfnln/eMydqln3cAQO7dcccdWSYDcnPMzcm1jNdXmtvExsYqMTExy/lSXuZQOcnqeH2t+0SS5s6dqzp16sjNzU0lS5ZU6dKltWzZMrvle/furTvvvFNt2rRRuXLl1LVr10zPODx69KhWrFiRaR6T8QyQGz2XyWkec99996lDhw4aMWKESpUqpfbt22v27NmZnnmXE2dn5xyfdXK5qlWrZiq78847b+g8Rvr/ufzlnztfX195eXlZc50MuZm358Rk8fiAPn366Pvvv9fChQvVsWNHhYWFafXq1Spbtqzdbdzc3d2zPJEkSRcvXsx0QtDHx0eNGze2/u2++uqratmypVq2bKlRo0ZpzZo1+vLLL/XII48oNDRUcXFxWfb1Wp+5CQDXS8bzYufPny9J+u2337Rx40Z17NhRTk5Okq7vuZOMY8SlP2aSsv7+ez3Ol2S1/qpVq1qJzAwZt8q80jHqen7X5vxQ1jg/9P/y+/xQVnOqS124cEEPPfSQzp07p2+//dbuFqUZc6as5rYXL160i5H+S7jXq1dPgYGBcnR01M8//6xp06Zp0qRJOnv2rEJDQ/XII49o8eLFioiIyPJ2+sYY5lS3CZ7xB+QDT09PlS1bVnv37s0xbu/evbrjjjtks9nsynP7a5prlTFBvdylB7F33nlHb775prp27apRo0bJ29tbjo6O6tevn9LT0697n1JSUnTkyBG753n07dtXs2fPVr9+/RQcHCxPT085ODioY8eOuepDXFyc7rvvPtlsNo0cOVKVK1eWm5ubdu3apVdffdWujfHjx+u5557Tt99+q1WrVumll17SmDFjtHXrVpUrV07p6elycHDQDz/8kOX+u5b7tF/J/v37JeV8YvLJJ59U06ZN9fXXX2vVqlV677339O677+qrr77K9ZUM1/vzl90E4/IHZ99oufm8AwByL6vjRV6Oudm5lvH6ZhjrLz9eX4998sUXX+i5557TI488okGDBqlMmTJycnLSmDFj9Msvv1hxZcqU0Z49e7Ry5Ur98MMP+uGHHzR79mw9++yzmjt3rqT/Tkw+8MADdr8+vlTGCZrrLas53uUcHBy0ZMkSbd26Vd9//71Wrlyprl27avz48dq6dWuu5lmXXnFxvTg4OGT5Gboec5ncnoi52s92xrMtLz+RlZycrFmzZmnw4MF2+6tIkSJq06aNpkyZouTkZLm4uKhs2bJKS0tTbGysypQpY9fGmTNncnxu1datW7VkyRLr38WCBQv05ptvKjg4WMHBwfroo4+0dOlS64TrpX299Jk4AFCQgoKCVL16dS1YsECvv/66FixYIGOMlRCU8v/cSYZrPV9yPdyo+Rfnh7LH+aFrcy3zqpySg8nJyXrssce0d+9erVy5MtO819vbW66urvrzzz8zLZtRltO8qn///nrmmWfUoEEDff755/L29taQIUMkSYMHD9bo0aM1YsQIu2X++ecf5lS3CRJ/QD556KGH9PHHH2vTpk1q0qRJpvqNGzfq5MmTdpfB54W/v7/S09N14sQJu18qHzt27Kr7nJUlS5bo/vvv16xZs+zK4+LibsiBY8mSJUpMTFRISIhdWZcuXTR+/Hir7OLFi5l+HZzdBGLdunU6c+aMvvrqKzVr1swqP3HiRJbxtWvXVu3atTV06FBt2bJF9957r2bMmKG3335blStXljFGAQEBVzwxdj1/UXP+/Hl9/fXXKl++fLYP4M5QtmxZ9e7dW71791ZsbKwaNGig0aNHWxO769mvP/74QxcuXLD7VdeRI0ckyXp4csYvpy7/e13+K8G89C3jQcqHDx/OVPfzzz+rVKlSmX5pBgC48fJ6zM1vZcqUkZubW5bzpes1h/r888/l4OCgBx54QFLe9kl2x8ElS5aoUqVK+uqrr+xi3nrrrUyxLi4uateundq1a6f09HT17t1bH330kd58801VqVJFlStX1vnz560r/LJzvX8ZnNUcLzuNGzdW48aNNXr0aM2fP19hYWFauHChunfvft37dfTo0UxlR44cseYx0n9zmax+IX/5XCYvfcuYyx89etRubhcTE6O4uDhrrnOtKlSoIHd390yftzNnzig1NTXLE20pKSlKT0+36urVqydJ2rlzp9q2bWvF7dy5U+np6Vb95Ywxeumll/Tyyy9bV6388ccfdie0/Pz89Pvvv9stl9HXK815ASA/hYWF6c0339TevXs1f/58Va1aVXfddZdVfz3PnWQcI3755Re7q5iy+v57redLslv/3r17lZ6ebvfjkIzbYF6vY9SVcH4oa5wfspef54eqV6+u//3vf1nWpaen69lnn9WaNWu0aNEi3XfffZliHB0dVbt2be3cuTNT3bZt21SpUqVsr+JcunSptmzZYs1d//jjD5UtW9aqz2pOJf332a5bt26utg+3Nm71CeSTQYMGyd3dXS+++KL1bI0MZ8+eVc+ePVW0aFENGjToqtrPmPhMmzbNrnzy5MlX1+FsODk5ZfrFy+LFi7M8mFyrn376Sf369VOJEiUUHh6eYx8mT56c6URFxoH88glExi95Lm0jOTk5075LSEhQamqqXVnt2rXl6OhoXYb/2GOPycnJSSNGjMjUJ2OM3d+6WLFi1+V2qImJiercubPOnj2rN954I8dfSF2+vjJlysjPz8/uNgLXq1+SlJqaqo8++sh6n5ycrI8++kilS5dWUFCQJFknei59ZlBaWppmzpyZqb3c9q1s2bKqV6+e5s6da/f33r9/v1atWmV3UgoAkH9ye8wtKE5OTmrVqpW++eYbu+edHDt2TD/88MM1tz927FitWrVKTz31lPXDrLzsk+yOg1m1sW3bNkVGRtrFXT7ndHR0VJ06dST9/y2FnnzySUVGRmrlypWZ1hMXF2fNhYoWLWqVXavs5niX++effzLNrzKSShn9v579kqRvvvnGbl67fft2bdu2ze6X8JUrV9bPP/+sv/76yyr76aefMj2fLi99y5irTJw40a78gw8+kCSFhobmaTuyU6RIETVs2DDTCaYyZcrIy8tLX3/9td1tPM+fP6/vv/9e1atXt37l36JFC3l7e2v69Ol2bUyfPl1FixbNtq9z5szR6dOn9cYbb1hlPj4+1onjlJQUHTt2TL6+vnbLRUVFydPTUzVr1rz6DQeA6yzj6r5hw4Zpz549dlf7Sdf33EnGMejDDz+0K7/8mJHdevNyviQrbdu2VXR0tL788kurLDU1VZMnT5aHh0eWCY3rjfNDWeP8UGb5eX4oODhY//zzT5Y/COvbt6++/PJLTZs2TY899li2bTz++OPasWOH3dzs8OHDWrt2rZ544oksl0lOTtaAAQM0dOhQ6+4LPj4+OnbsmPU5PXToUKY5VXx8vH755Rfdc889ed5W3Hq44g/IJ1WrVtXcuXMVFham2rVrq1u3bgoICNDJkyc1a9Ys/f3331qwYEGme7bnVlBQkDp06KCJEyfqzJkzaty4sdavX2/9muZ6/WrnoYce0siRI/X888/rnnvu0b59+zRv3jxVqlTpmtrduHGjLl68aD30evPmzfruu+/k6empr7/+2u5g9dBDD+nzzz+Xp6enAgMDFRkZqdWrV1u3LspQr149OTk56d1331V8fLxcXV3VokUL3XPPPSpRooS6dOmil156SQ4ODvr8888zTczWrl2rPn366IknntCdd96p1NRUff7553JyclKHDh0k/TdJefvttzVkyBCdPHlSjzzyiIoXL64TJ07o66+/Vo8ePfTKK69I+u9v9OWXX2rAgAG666675OHhoXbt2uW4X37//Xd98cUXkv478XLw4EEtXrxY0dHRGjhwYI5XiJ47d07lypXT448/rrp168rDw0OrV6/Wjh077H4NdzX9yo6fn5/effddnTx5Unfeeae+/PJL7dmzRzNnzlSRIkUkSTVr1lTjxo01ZMgQnT17Vt7e3lq4cGGmSXRe+/bee++pTZs2Cg4OVrdu3ZSYmKjJkyfL09NTw4cPv6rtAQBcm9wecwvS8OHDtWrVKt17773q1auX0tLSNGXKFNWqVUt79uzJVRupqanW8frixYv69ddf9d1332nv3r26//777U5e5GWfZHccfOihh/TVV1/p0UcfVWhoqE6cOKEZM2YoMDDQesaLJHXv3l1nz55VixYtVK5cOf3666+aPHmy6tWrZ/0ifNCgQfruu+/00EMP6bnnnlNQUJAuXLigffv2acmSJTp58qRKlSold3d3BQYG6ssvv9Sdd94pb29v1apVK8dbdUp5m+Ndbu7cuZo2bZoeffRRVa5cWefOndPHH38sm81mnbS52n5lp0qVKmrSpIl69eqlpKQkTZw4USVLlrS7FWrXrl31wQcfKCQkRN26dVNsbKxmzJihmjVrKiEhwYrLS9/q1q2rLl26aObMmdZtx7Zv3665c+fqkUce0f33339V25OV9u3b64033lBCQoL1iAEnJye98sorGjp0qBo3bqxnn31WaWlpmjVrln777Tfr852xXaNGjVJ4eLieeOIJhYSEaOPGjfriiy80evRoeXt7Z1rnuXPn9Prrr+udd96x++X6448/rpEjRyo9PV2bN2/WxYsXM52Qi4iIULt27XgeDYCbSkBAgO655x59++23kpQp8Xc9z53Uq1dPnTp10rRp0xQfH6977rlHa9asyfLuBNd6vuTSWzhn6NGjhz766CM999xzioqKUsWKFbVkyRJt3rxZEydOzPG5cleD80NZ4/zQzXd+KDQ0VM7Ozlq9erV69OhhlU+cOFHTpk1TcHCwihYtajePkqRHH33USkb37t1bH3/8sUJDQ/XKK6+oSJEi+uCDD+Tj46OBAwdmud5JkyZJkt0zmNu2bavw8HA9/fTTuueeezRq1Ch1797dbrnVq1fLGKP27dtfl+3HTc4AyFd79+41nTp1MmXLljVFihQxvr6+plOnTmbfvn2ZYt966y0jyfz111/Z1l3qwoULJjw83Hh7exsPDw/zyCOPmMOHDxtJZuzYsVbc7NmzjSRz4sQJq8zf39+EhoZmWs99991n7rvvPuv9xYsXzcCBA03ZsmWNu7u7uffee01kZGSmuBMnThhJZvbs2Tnujx9//NFIsl5FihQxpUuXNs2aNTOjR482sbGxmZb5559/zPPPP29KlSplPDw8TEhIiPn555+Nv7+/6dKli13sxx9/bCpVqmScnJyMJPPjjz8aY4zZvHmzady4sXF3dzd+fn5m8ODBZuXKlXYxx48fN127djWVK1c2bm5uxtvb29x///1m9erVmfr0v//9zzRp0sQUK1bMFCtWzFSvXt2Eh4ebw4cPWzHnz583Tz/9tPHy8jKSjL+/f477xt/f39ovDg4OxmazmZo1a5oXXnjBbNu2LctlJJm33nrLGGNMUlKSGTRokKlbt64pXry4KVasmKlbt66ZNm2a3TLZ9Svjb7N48eJM68moy9hXxvz3WalZs6bZuXOnCQ4ONm5ubsbf399MmTIl0/K//PKLadWqlXF1dTU+Pj7m9ddfNxEREZnazK5v2X2+Vq9ebe69917j7u5ubDabadeunTl48KAxxpjffvvNhIWFGTc3NyPJVK9e3ezYscNa9tNPPzWSTKlSpYybm5tp2bKlOXLkiF37Z86cMU8//bQpXry48fT0NF27djXnzp3L8m+RITEx0fTu3dt4e3ubYsWKmccee8xER0fbxfz666+mbdu2xt3d3ZQuXdq88sorJiUlJdM+r1+/vnFxcTGVK1e+4r8tAMirjLnFpa9q1apligsPDzeSzP79+81jjz1mHa98fX0zxb7zzjumevXqxtHR0Ugybm5upnv37nbH3Ixx0sXFxTg4OFjjZMZY/95772Vq99Lj3aV9vzwmPDw807JZzRfWrFljN8Z+8sknZuDAgcbNze2K+61Lly52+6xo0aKmYsWKpkOHDmbJkiUmLS0t0zK5mYcYk/1xMD093bzzzjvG39/fuLq6mvr165ulS5eaLl262M0vlixZYlq3bm3KlCljXFxcTIUKFcyLL75o/vzzT7v+nDt3zgwZMsRUqVLFuLi4mFKlSpl77rnHvP/++yY5OdmK27JliwkKCjIuLi6Z/gaXu5o53uVz1F27dplOnTqZChUqGFdXV1OmTBnz0EMPmZ07d9otl12/unTpYooVK5Zl/y7fV5d+3saPH2/Kly9vXF1dTdOmTc1PP/2UafkvvvjCVKpUybi4uJh69eqZlStXZmozp75l9ZlNSUkxI0aMMAEBAaZIkSKmfPnyZsiQIebixYt2cbmdt2cnJibGODs7m88//zxT3bx588zdd99tvLy8jLu7u2nUqJFZsmSJXUxWY0WRIkXMhAkTTHp6eqY29+/fb6pWrWrtgwkTJlh158+fN88++6xxc3OzXqVLlzbt27c3P//8szl06JCRZFavXp2rORUA5If169ebhx56yNhsNiPJVK1aNVPMpedOXFxcjKenp/H09DROTk6mePHiZsWKFcaY/z/+zJo1ywwdOtRUrFjROn8xcuRIa1xNTEw0ffv2Ne7u7sbBwcE4Ojqae++9N9Px+HqcL8nqeBITE2O16+LiYmrXrp3pO2le5m5Z4fxQ9jg/dH3PD2XI7rxrVudNs/Pwww+bli1b2pVd/v3g8tfl7Z4+fdo8/vjjxmazGTc3N1OqVClTokQJU7x4cdO4cWNrvDDGmOjoaFO8eHHz5JNPmooVKxo3NzdTqVIlM3LkSLN8+XJTvXp14+XlZZ599lnz2muvGV9fX+scV9u2bU2TJk2uuE0oHEj8AYXc7t27jSTzxRdfFHRXgAJz9uxZ4+/vb5577jmzbds2c/z4cbNy5Upz7NgxK2bs2LHG09PTfPPNN+ann34yDz/8sAkICDCJiYlWzIMPPmjq1q1rtm7dajZu3GiqVKliOnXqlOO6e/bsacqXL2/WrFljdu7caRo3bmzuueceqz41NdXUqlXLtGrVyuzevdssX77clCpVygwZMsSKOX78uClatKgZMGCAOXjwoJk8ebJxcnKym/wBwLV66623TM2aNc2ff/5pvbL68VGG7du3m1deecUsWLDA+Pr62p3MzxASEmJmz55t9u/fb/bs2WPatm1rKlSoYM6fP2/FXGmcLCjt27c3VapUKehuADdE165dr/rET36OFb179zb169c36enpN+1YAeD2s3z5cvPGG2+Yr776ykgyX3/9dY7xL7/8snn33XfN9u3bzZEjR8yQIUNMkSJFzK5du6yY0aNHm5IlS5qlS5eaEydOmMWLFxsPDw8zadIkKyY331kB5K8NGzYYR0fHTD8cz3CzjBetW7c2Dg4OZtGiRddlu3HzI/EHFCL//vtvprIuXboYR0dHc+rUqQLoEXBzePXVV3M8uZWenm58fX3tfpkYFxdnXF1dzYIFC4wxxhw8eNBIsrtK8IcffjAODg7m999/z7LduLg4U6RIEbtfxWX8cj0yMtIY898k0NHR0e4X69OnTzc2m80kJSUZY4wZPHiwqVmzpl3bTz31lAkJCcntLgCAK3rrrbdM3bp1r2pZf3//LE/mXy42NtZIMuvXrzfG5G6czA+Xz6GOHDliihQpYrp3755vfQDy06+//mpcXV3Npk2b8rxsfo4V7u7uZtmyZTfNWAEAl8vNifysBAYGmhEjRljvQ0NDTdeuXe1iHnvsMRMWFmaMyd13VgAF48EHH8zV94aCHC/69etnHBwcGC9uI45XvhkogFvFuHHj9PDDD2vChAmaPHmy2rZtq7lz56p79+4qX758QXcPKDDfffedGjZsqCeeeEJlypRR/fr19fHHH1v1J06cUHR0tFq1amWVeXp6qlGjRoqMjJQkRUZGysvLSw0bNrRiWrVqJUdHR23bti3L9UZFRSklJcWu3erVq6tChQp27dauXVs+Pj5WTEhIiBISEnTgwAEr5tI2MmIy2gCA6+Xo0aPy8/NTpUqVFBYWplOnTl3X9uPj4yXJegZYbsbJ/FCpUiUNGTJEH3/8sfWMMxcXF7vnugGFSYUKFXTx4kXde++9V7V8fo0V27dvV9u2bW+asQIArof09HSdO3fO7pmoGc/tO3LkiCTpp59+0qZNm9SmTRtJufvOCqBg/PDDD3bnmK6n6zVeTJgwQU2bNmW8uI04F3QHAFw/99xzjyIiIjRq1CidP39eFSpU0PDhw/XGG28UdNeAAnX8+HFNnz5dAwYM0Ouvv64dO3bopZdekouLi7p06aLo6GhJsku+ZbzPqIuOjs70oHNnZ2d5e3tbMZeLjo6Wi4uLvLy8cmw3q/Vm1OUUk5CQoMTERLm7u+d2VwBAtho1aqQ5c+aoWrVq+vPPPzVixAg1bdpU+/fvV/Hixa+5/fT0dPXr10/33nuvatWqJSl342R+ePDBB7VgwQJFR0fL1dVVwcHBeuedd1S1atV86wNwq7idxwoAuB7ef/99nT9/Xk8++aRV9tprrykhIUHVq1eXk5OT0tLSNHr0aIWFhUlSrr6zAih8GC9wtUj8AYXIAw88oAceeKCguwHcdNLT09WwYUO98847kqT69etr//79mjFjhrp06VLAvQOAm0PGL0QlqU6dOmrUqJH8/f21aNEidevW7ZrbDw8P1/79+7Vp06Zrbut6mz17dkF3Abhl3M5jBQBcq/nz52vEiBH69ttv7X5YumjRIs2bN0/z589XzZo1tWfPHvXr109+fn58ZwVuU4wXuBbc6hMAUOiVLVtWgYGBdmU1atSwbkvl6+srSYqJibGLiYmJsep8fX0VGxtrV5+amqqzZ89aMZfz9fVVcnKy4uLicmw3q/Ve2q/sYmw2G1f7AbhhvLy8dOedd+rYsWPX3FafPn20dOlS/fjjjypXrpxVnptxEsDNjbECAHJn4cKF6t69uxYtWpTpUQ6DBg3Sa6+9po4dO6p27drq3Lmz+vfvrzFjxkjK3XdWAIUH4wWuFYk/AEChd++99+rw4cN2ZUeOHJG/v78kKSAgQL6+vlqzZo1Vn5CQoG3btik4OFiSFBwcrLi4OEVFRVkxa9euVXp6uho1apTleoOCglSkSBG7dg8fPqxTp07Ztbtv3z67pGJERIRsNpuVrAwODrZrIyMmow0AuBHOnz+vX375RWXLlr3qNowx6tOnj77++mutXbtWAQEBdvW5GScB3NwYKwDgyhYsWKDnn39eCxYsUGhoaKb6f//9V46O9qdpnZyclJ6eLil331kBFA6MF7geuNVnDtLT0/XHH3+oePHicnBwKOjuAACu0gsvvKDWrVtr2LBhevTRR7Vr1y7NnDlTkyZNUkJCgiSpZ8+eGjVqlO644w75+/tr9OjR8vX1VYsWLZSQkKA77rhDrVq1UteuXTVx4kSlpKSod+/e6tChgzw8PKx2LuXg4GD98srV1VXFixfX4MGDdffddyswMFAJCQlq3Lixqlevrk6dOmnkyJGKiYnRG2+8oe7duyspKUlJSUkKCwvTlClT9PLLL6tz585av369Fi1apEWLFmW5XtwcjDE6d+6c/Pz8Mk3KCyPmTbe+N954Q23atFH58uUVHR2td955R46OjnrooYeyHGuSk5P1888/S5KSkpJ0/Phxbdq0ScWKFVPlypUlSQMGDNCSJUs0f/58SdLRo0clybpiOTfjJICbC2MFrjfmTLjVnD9/XsePH7feHzp0SKVKlVKJEiVUvnz5TPGLFy9Wz549NXbsWAUGBlpjnJubmzw9PSX997zht99+W6VKlVL16tW1d+9ejR8/Xs8880yuv7MCuPkwXuB6ysucycEYY/KpX7ec3377Lct/gAAAALl1+vRpu9uVFVbMmwAAwLVgzgQAAHBluZkzccVfDooXLy7pvx1ps9kKuDcAgJvdyZMnFRQUpO3bt1u/YMftKyEhQeXLl7fmE4Ud86bCr23btmratKmGDBlS0F0BcBNjrEBeMWdCYdOzZ085ODho+vTpBd0VADc5xgvkRV7mTCT+cpBxywWbzcZkDABwRRs3blSPHj1Uv379gu4KbiK3yy2cmDcVbvHx8Tp58qRWrFghDw+Pgu4OgJsUYwWuBXMmFAbGGG3evFmbNm3i7wsgR4wXuFq5mTOR+AMA4DoJDw8v6C4AwA3h6emp3377raC7AeAmx1gB4Hbn4OCgX3/9taC7AeAWwHiBG6nwPzUZAAAAAAAAAAAAuA2Q+AMAAAAAAAAAAAAKARJ/AAAAAAAAAAAAQCFA4g8AcFs5c+aMypQpo5MnTxZ0V/JsxYoVqlevntLT0wu6KwBuUbfyGDhjxgy1a9euoLsB3DYYLwDc7hgHAeQGYwVuRiT+AAC3ldGjR6t9+/aqWLGiVTZnzhzVqVNHbm5uKlOmjMLDw+2W2bt3r5o2bSo3NzeVL19e48aNu+J6Tp06pdDQUBUtWlRlypTRoEGDlJqaatXv3r1b9evXl4eHh9q1a6ezZ89adampqQoKCtL27dvt2nzwwQdVpEgRzZs37yq3HsDt7vIx0MHBIdNr4cKFdsusW7dODRo0kKurq6pUqaI5c+ZccT1XGjcjIiJ05513ymazqXPnzkpOTrbq4uPjdeedd2Z60H3Xrl21a9cubdy48eo2HkCeMF4AuN0xDgLIDcYK3JQMshUfH28kmfj4+ILuCgDgOrhw4YKx2WwmMjLSKhs/frzx8/Mz8+bNM8eOHTM//fST+fbbb636+Ph44+PjY8LCwsz+/fvNggULjLu7u/noo4+yXU9qaqqpVauWadWqldm9e7dZvny5KVWqlBkyZIgV06BBAzNgwABz+PBh07RpUzNw4ECrbuzYsaZv375Ztj1lyhTTsGHDa9kNyCe32zzidtveW1FWY6AkM3v2bPPnn39ar8TERKv++PHjpmjRombAgAHm4MGDZvLkycbJycmsWLEi2/VcadxMS0szpUqVMuPHjzf79+831atXN5MnT7aW79mzpxk/fnyWbb/yyivm8ccfv9ZdAeAKGC+Qn263OcTttr23KsZBALnBWIH8lJc5BIm/HDAZA4DCZfHixaZ06dLW+7Nnzxp3d3ezevXqbJeZNm2aKVGihElKSrLKXn31VVOtWrVsl1m+fLlxdHQ00dHRVtn06dONzWaz2nF3dzeHDh2y1tG2bVtjjDG//PKLqVq1qklISMiy7V9//dVIMseOHcvFFqMg3W7ziNtte29Fl4+Bxvz3pfTrr7/OdpnBgwebmjVr2pU99dRTJiQkJNtlrjRuxsTEGEnWl9/Bgweb3r17G2OM2bx5swkKCjKpqalZtr1+/Xrj4uJi/v333+w3FMA1Y7xAfrrd5hC32/beqhgHAeQGYwXyU17mENzqEwBw29i4caOCgoKs9xEREUpPT9fvv/+uGjVqqFy5cnryySd1+vRpKyYyMlLNmjWTi4uLVRYSEqLDhw/rn3/+yXI9kZGRql27tnx8fOyWSUhI0IEDByRJdevWVUREhFJTU7VmzRrVqVNHktSzZ0+NGzdOxYsXz7LtChUqyMfHh9swAMizy8fADOHh4SpVqpTuvvtuffrppzLGWHWRkZFq1aqVXXxISIgiIyOzXc+Vxs3SpUurbNmyWrVqlf79919t3LhRderUUUpKinr16qWPPvpITk5OWbbdsGFDpaamatu2bXndfAB5wHgB4HbHOAggNxgrcLMi8QcAuG38+uuv8vPzs94fP35c6enpeueddzRx4kQtWbJEZ8+e1QMPPGDdCz06OtougSfJeh8dHZ3lenKzzCeffKIlS5aocuXKcnFx0ZAhQ/T555+raNGiuuuuuxQSEqIqVapo6NChmdr38/PLdF92ALiSy8dASRo5cqQWLVqkiIgIdejQQb1799bkyZOt+uzGs4SEBCUmJma5niuNgQ4ODlq0aJFGjRqlmjVrqn79+uratavGjh2r+++/X25ubrr33ntVrVo1TZkyxa6dokWLytPTkzEQuMEYLwDc7hgHAeQGYwVuVs4F3QEAAPJLYmKi3NzcrPfp6elKSUnRhx9+qNatW0uSFixYIF9fX/34448KCQm5YX2pWbOm1q9fb70/c+aM3nrrLW3YsEF9+/bVPffco6+++kp33XWXGjVqpHbt2lmx7u7u+vfff29Y3wAUTpePgZL05ptvWv9fv359XbhwQe+9955eeumlG9qXJk2aaMeOHdb7I0eO6LPPPtPu3bvVrFkzvfzyy2rTpo1q1aqlZs2aWVdFS4yBQH5gvABwu2McBJAbjBW4WXHFHwDgtlGqVCm723OWLVtWkhQYGGiVlS5dWqVKldKpU6ckSb6+voqJibFrJ+O9r69vluu5mmUGDBigfv36qVy5clq3bp2eeOIJFStWTKGhoVq3bp1d7NmzZ1W6dOkrbS4A2Ll8DMxKo0aN9NtvvykpKUlS9uOZzWaTu7t7lm1czRj44osvavz48UpPT9fu3bv1xBNPqEyZMrrvvvvsfiQhMQYC+YHxAsDtjnEQQG4wVuBmReIPAHDbqF+/vg4ePGi9v/feeyVJhw8ftsrOnj2rv//+W/7+/pKk4OBgbdiwQSkpKVZMRESEqlWrphIlSmS5nuDgYO3bt0+xsbF2y9hsNrskY4Y1a9bo0KFD6tOnjyQpLS3NWl9KSorS0tKs2IsXL+qXX35R/fr187z9AG5vl4+BWdmzZ49KlCghV1dXSf+NZ2vWrLGLiYiIUHBwcLZt5HXcnDVrlry9vfXwww9b4112Y+Avv/yiixcvMgYCNxjjBYDbHeMggNxgrMBNy+TRb7/9ZsLCwoy3t7dxc3MztWrVMjt27LDq09PTzZtvvml8fX2Nm5ubadmypTly5IhdG2fOnDFPP/20KV68uPH09DRdu3Y1586ds4v56aefTJMmTYyrq6spV66ceffddzP1ZdGiRaZatWrG1dXV1KpVyyxbtsyuPjd9yUl8fLyRZOLj43O9DADg5rV3717j7Oxszp49a5W1b9/e1KxZ02zevNns27fPPPTQQyYwMNAkJycbY4yJi4szPj4+pnPnzmb//v1m4cKFpmjRouajjz6y2vjqq69MtWrVrPepqammVq1apnXr1mbPnj1mxYoVpnTp0mbIkCGZ+pSYmGiqV69udu/ebZW1adPGvPDCC2bPnj2mXLlyZtGiRVbdjz/+aDw8PMyFCxeu567BDXC7zSNut+29FV0+Bn733Xfm448/Nvv27TNHjx4106ZNM0WLFjXDhg2zljl+/LgpWrSoGTRokDl06JCZOnWqcXJyMitWrLBiJk+ebFq0aGG9z824mSEmJsZUrFjR/P7771ZZjRo1zPDhw82WLVuMh4eH2b59u1U3e/ZsU6lSpeu6XwBkxniB/HS7zSFut+29VTEOAsgNxgrkp7zMIfKU+Dt79qzx9/c3zz33nNm2bZs5fvy4WblypTl27JgVM3bsWOPp6Wm++eYb89NPP5mHH37YBAQEmMTERCvmwQcfNHXr1jVbt241GzduNFWqVDGdOnWy2wAfHx8TFhZm9u/fbxYsWGDc3d3tPsibN282Tk5OZty4cebgwYNm6NChpkiRImbfvn156ktOmIwBQOFz9913mxkzZljv4+PjTdeuXY2Xl5fx9vY2jz76qDl16pTdMpf+GOWOO+4wY8eOtaufPXu2ufy3NCdPnjRt2rQx7u7uplSpUmbgwIEmJSUlU39ee+01M3DgQLuyo0ePmrvuusvYbDbTq1cvk5aWZtX16NHDvPjii1e9/cg/t9s84nbb3lvVpWPgDz/8YOrVq2c8PDxMsWLFTN26dc2MGTPsxhxj/vvBQb169YyLi4upVKmSmT17tl39W2+9Zfz9/e3KrjRuZujYsaOZPHmyXdm2bdtM9erVjbe3txkxYoRdXevWrc2YMWOuYssB5BXjBfLL7TaHuN2291bGOAggNxgrkF/yModwMMaY3F4d+Nprr2nz5s3auHFjdlcPys/PTwMHDtQrr7wiSYqPj5ePj4/mzJmjjh076tChQwoMDNSOHTvUsGFDSdKKFSvUtm1b/fbbb/Lz89P06dP1xhtvKDo6Wi4uLta6v/nmG/3888+SpKeeekoXLlzQ0qVLrfU3btxY9erV04wZM3LVlytJSEiQp6en4uPjZbPZcrubAAA3sWXLlmnQoEHav3+/HB1vrTte//3336pWrZp27typgICAgu4OruB2m0fcbtt7q7qVx8ADBw6oRYsWOnLkiDw9PQu6O0Chx3iB/HK7zSFut+29lTEOAsgNxgrkl7zMIfL0Sfzuu+/UsGFD60GQ9evX18cff2zVnzhxQtHR0WrVqpVV5unpqUaNGikyMlKSFBkZKS8vLyvpJ0mtWrWSo6Ojtm3bZsU0a9bMSvpJUkhIiA4fPmw9LDMyMtJuPRkxGevJTV8AALef0NBQ9ejRQ7///ntBdyXPTp48qWnTppH0A3DVbuUx8M8//9Rnn33GF1IgnzBeALjdMQ4CyA3GCtyMnPMSfPz4cU2fPl0DBgzQ66+/rh07duill16Si4uLunTpoujoaEmSj4+P3XI+Pj5WXXR0tMqUKWPfCWdneXt728VcflIzo83o6GiVKFFC0dHRV1zPlfpyuaSkJCUlJVnvExISrrBHAAC3on79+hV0F65Kw4YN7X44AwBX41YdAy//0R+AG4/xAsDtjnEQQG4wVuBmk6fEX3p6uho2bKh33nlHklS/fn3t379fM2bMUJcuXW5IB/PTmDFjNGLEiILuBgBkqeJrywq6C0Chc3JsaEF3AXnAOAhcX4V1DGSsAK6/wjpeFFaMg8D1VxjHQcYK4Pq7WcaKPN3qs2zZsgoMDLQrq1Gjhk6dOiVJ8vX1lSTFxMTYxcTExFh1vr6+io2NtatPTU3V2bNn7WKyauPSdWQXc2n9lfpyuSFDhig+Pt56nT59Oss4AAAAAAAAAAAA4GaTp8Tfvffeq8OHD9uVHTlyRP7+/pKkgIAA+fr6as2aNVZ9QkKCtm3bpuDgYElScHCw4uLiFBUVZcWsXbtW6enpatSokRWzYcMGpaSkWDERERGqVq2aSpQoYcVcup6MmIz15KYvl3N1dZXNZrN7AQAAAAAAAAAAALeCPCX++vfvr61bt+qdd97RsWPHNH/+fM2cOVPh4eGSJAcHB/Xr109vv/22vvvuO+3bt0/PPvus/Pz89Mgjj0j67wrBBx98UC+88IK2b9+uzZs3q0+fPurYsaP8/PwkSU8//bRcXFzUrVs3HThwQF9++aUmTZqkAQMGWH15+eWXtWLFCo0fP14///yzhg8frp07d6pPnz657gsAAAAAAAAAAABQWOQp8XfXXXfp66+/1oIFC1SrVi2NGjVKEydOVFhYmBUzePBg9e3bVz169NBdd92l8+fPa8WKFXJzc7Ni5s2bp+rVq6tly5Zq27atmjRpopkzZ1r1np6eWrVqlU6cOKGgoCANHDhQw4YNU48ePayYe+65x0o81q1bV0uWLNE333yjWrVq5akvAAAAN6vhw4fLwcHB7lW9enWr/uLFiwoPD1fJkiXl4eGhDh06ZLrN+alTpxQaGqqiRYuqTJkyGjRokFJTU+1i1q1bpwYNGsjV1VVVqlTRnDlz8mPzAAAAAAAAcJ0553WBhx56SA899FC29Q4ODho5cqRGjhyZbYy3t7fmz5+f43rq1KmjjRs35hjzxBNP6IknnrimvgAAANzMatasqdWrV1vvnZ3/f/rWv39/LVu2TIsXL5anp6f69Omjxx57TJs3b5YkpaWlKTQ0VL6+vtqyZYv+/PNPPfvssypSpIjeeecdSdKJEycUGhqqnj17at68eVqzZo26d++usmXLKiQkJH83FgAAAAAAANckz4k/AAAA5B9nZ2f5+vpmKo+Pj9esWbM0f/58tWjRQpI0e/Zs1ahRQ1u3blXjxo21atUqHTx4UKtXr5aPj4/q1aunUaNG6dVXX9Xw4cPl4uKiGTNmKCAgQOPHj5f0323ZN23apAkTJpD4AwAAAAAAuMXk6VafAAAAyF9Hjx6Vn5+fKlWqpLCwMJ06dUqSFBUVpZSUFLVq1cqKrV69uipUqKDIyEhJUmRkpGrXri0fHx8rJiQkRAkJCTpw4IAVc2kbGTEZbQAAAAAAAODWwRV/AAAAN6lGjRppzpw5qlatmv7880+NGDFCTZs21f79+xUdHS0XFxd5eXnZLePj46Po6GhJUnR0tF3SL6M+oy6nmISEBCUmJsrd3T3LviUlJSkpKcl6n5CQcE3bCgAAAAAAgGtH4g8AAOAm1aZNG+v/69Spo0aNGsnf31+LFi3KNiGXX8aMGaMRI0YUaB8AAAAAAABgj1t9AgAA3CK8vLx055136tixY/L19VVycrLi4uLsYmJiYqxnAvr6+iomJiZTfUZdTjE2my3H5OKQIUMUHx9vvU6fPn2tmwcAAAAAAIBrROIPAADgFnH+/Hn98ssvKlu2rIKCglSkSBGtWbPGqj98+LBOnTql4OBgSVJwcLD27dun2NhYKyYiIkI2m02BgYFWzKVtZMRktJEdV1dX2Ww2uxcAAAAAAAAKFok/AACAm9Qrr7yi9evX6+TJk9qyZYseffRROTk5qVOnTvL09FS3bt00YMAA/fjjj4qKitLzzz+v4OBgNW7cWJLUunVrBQYGqnPnzvrpp5+0cuVKDR06VOHh4XJ1dZUk9ezZU8ePH9fgwYP1888/a9q0aVq0aJH69+9fkJsOAAAAAACAq8Az/gAAAG5Sv/32mzp16qQzZ86odOnSatKkibZu3arSpUtLkiZMmCBHR0d16NBBSUlJCgkJ0bRp06zlnZyctHTpUvXq1UvBwcEqVqyYunTpopEjR1oxAQEBWrZsmfr3769JkyapXLly+uSTTxQSEpLv2wsAAAAAAIBrQ+IPAADgJrVw4cIc693c3DR16lRNnTo12xh/f38tX748x3aaN2+u3bt3X1UfAQAAAAAAcPPgVp8AAAAAAAAAAABAIUDiDwAAAAAAAAAAACgESPwBAAAAAAAAAAAAhQCJPwAAAAAAAAAAAKAQIPEHAAAAAAAAAAAAFAIk/gAAAAAAAHDL2rBhg9q1ayc/Pz85ODjom2++sepSUlL06quvqnbt2ipWrJj8/Pz07LPP6o8//rBr4+zZswoLC5PNZpOXl5e6deum8+fP28Xs3btXTZs2lZubm8qXL69x48blx+YBAADkCYk/AAAAAAAA3LIuXLigunXraurUqZnq/v33X+3atUtvvvmmdu3apa+++kqHDx/Www8/bBcXFhamAwcOKCIiQkuXLtWGDRvUo0cPqz4hIUGtW7eWv7+/oqKi9N5772n48OGaOXPmDd8+AACAvHAu6A4AAAAAAAAAV6tNmzZq06ZNlnWenp6KiIiwK5syZYruvvtunTp1ShUqVNChQ4e0YsUK7dixQw0bNpQkTZ48WW3bttX7778vPz8/zZs3T8nJyfr000/l4uKimjVras+ePfrggw/sEoQAAAAFjSv+AAAAAAAAcNuIj4+Xg4ODvLy8JEmRkZHy8vKykn6S1KpVKzk6Omrbtm1WTLNmzeTi4mLFhISE6PDhw/rnn3/ytf8AAAA54Yo/AAAAAAAA3BYuXryoV199VZ06dZLNZpMkRUdHq0yZMnZxzs7O8vb2VnR0tBUTEBBgF+Pj42PVlShRIsv1JSUlKSkpyXqfkJBw3bYFAAAgK1zxBwAAAAAAgEIvJSVFTz75pIwxmj59er6sc8yYMfL09LRe5cuXz5f1AgCA2xeJPwAAAAAAABRqGUm/X3/9VREREdbVfpLk6+ur2NhYu/jU1FSdPXtWvr6+VkxMTIxdTMb7jJisDBkyRPHx8dbr9OnT12uTAAAAskTiDwAAAAAAAIVWRtLv6NGjWr16tUqWLGlXHxwcrLi4OEVFRVlla9euVXp6uho1amTFbNiwQSkpKVZMRESEqlWrlu1tPiXJ1dVVNpvN7gUAAHAjkfgDAAAAAADALev8+fPas2eP9uzZI0k6ceKE9uzZo1OnTiklJUWPP/64du7cqXnz5iktLU3R0dGKjo5WcnKyJKlGjRp68MEH9cILL2j79u3avHmz+vTpo44dO8rPz0+S9PTTT8vFxUXdunXTgQMH9OWXX2rSpEkaMGBAQW02AABAlpwLugMAAAAAAADA1dq5c6fuv/9+631GMq5Lly4aPny4vvvuO0lSvXr17Jb78ccf1bx5c0nSvHnz1KdPH7Vs2VKOjo7q0KGDPvzwQyvW09NTq1atUnh4uIKCglSqVCkNGzZMPXr0uLEbBwAAkEck/gAAAAAAAHDLat68uYwx2dbnVJfB29tb8+fPzzGmTp062rhxY577BwAAkJ+41ScAAAAAAAAAAABQCJD4AwAAAAAAAAAAAAoBEn8AAAAAAAAAAABAIUDiDwAAAAAAAAAAACgESPwBAAAAAAAAAAAAhQCJPwAAAAAAAAAAAKAQIPEHAAAAAAAAAAAAFAIk/gAAAAAAAAAAAIBCgMQfAAAAAAAAAAAAUAiQ+AMAAAAAAAAAAAAKARJ/AAAAAAAAAAAAQCFA4g8AAAAAAAAAAAAoBEj8AQAAAAAAAAAAAIUAiT8AAAAAAAAAAACgECDxBwAAAAAAAAAAABQCJP4AAAAAAAAAAACAQoDEHwAAAAAAAAAAAFAIkPgDAAAAAAAAAAAACgESfwAAAAAAAAAAAEAhQOIPAAAAAAAAAAAAKARI/AEAAAAAAAAAAACFAIk/AAAAAAAAAAAAoBAg8QcAAAAAAAAAAAAUAiT+AAAAAAAAAAAAgEKAxB8AAAAAAAAAAABQCJD4AwAAAAAAAAAAAAoBEn8AAAAAAAAAAABAIUDiDwAAAAAAAAAAACgESPwBAAAAAAAAAAAAhQCJPwAAAAAAAAAAAKAQIPEHAAAAAAAAAAAAFAJ5SvwNHz5cDg4Odq/q1atb9RcvXlR4eLhKliwpDw8PdejQQTExMXZtnDp1SqGhoSpatKjKlCmjQYMGKTU11S5m3bp1atCggVxdXVWlShXNmTMnU1+mTp2qihUrys3NTY0aNdL27dvt6nPTFwAAAAAAAAAAAKCwyPMVfzVr1tSff/5pvTZt2mTV9e/fX99//70WL16s9evX648//tBjjz1m1aelpSk0NFTJycnasmWL5s6dqzlz5mjYsGFWzIkTJxQaGqr7779fe/bsUb9+/dS9e3etXLnSivnyyy81YMAAvfXWW9q1a5fq1q2rkJAQxcbG5rovAAAAAAAAAAAAQGGS58Sfs7OzfH19rVepUqUkSfHx8Zo1a5Y++OADtWjRQkFBQZo9e7a2bNmirVu3SpJWrVqlgwcP6osvvlC9evXUpk0bjRo1SlOnTlVycrIkacaMGQoICND48eNVo0YN9enTR48//rgmTJhg9eGDDz7QCy+8oOeff16BgYGaMWOGihYtqk8//TTXfQEAAAAAAAAAAAAKkzwn/o4ePSo/Pz9VqlRJYWFhOnXqlCQpKipKKSkpatWqlRVbvXp1VahQQZGRkZKkyMhI1a5dWz4+PlZMSEiIEhISdODAASvm0jYyYjLaSE5OVlRUlF2Mo6OjWrVqZcXkpi8AAAAAAAAAAABAYeKcl+BGjRppzpw5qlatmv7880+NGDFCTZs21f79+xUdHS0XFxd5eXnZLePj46Po6GhJUnR0tF3SL6M+oy6nmISEBCUmJuqff/5RWlpaljE///yz1caV+pKVpKQkJSUlWe8TEhKusEcAAAAAAAAAAACAm0OeEn9t2rSx/r9OnTpq1KiR/P39tWjRIrm7u1/3zuW3MWPGaMSIEQXdDQAAAAAAAAAAACDP8nyrz0t5eXnpzjvv1LFjx+Tr66vk5GTFxcXZxcTExMjX11eS5Ovrq5iYmEz1GXU5xdhsNrm7u6tUqVJycnLKMubSNq7Ul6wMGTJE8fHx1uv06dO52xEAAAAAAAAAAABAAbumxN/58+f1yy+/qGzZsgoKClKRIkW0Zs0aq/7w4cM6deqUgoODJUnBwcHat2+fYmNjrZiIiAjZbDYFBgZaMZe2kRGT0YaLi4uCgoLsYtLT07VmzRorJjd9yYqrq6tsNpvdCwAAAAAAAAAAALgV5OlWn6+88oratWsnf39//fHHH3rrrbfk5OSkTp06ydPTU926ddOAAQPk7e0tm82mvn37Kjg4WI0bN5YktW7dWoGBgercubPGjRun6OhoDR06VOHh4XJ1dZUk9ezZU1OmTNHgwYPVtWtXrV27VosWLdKyZcusfgwYMEBdunRRw4YNdffdd2vixIm6cOGCnn/+eUnKVV8AAAAAAAAAAACAwiRPib/ffvtNnTp10pkzZ1S6dGk1adJEW7duVenSpSVJEyZMkKOjozp06KCkpCSFhIRo2rRp1vJOTk5aunSpevXqpeDgYBUrVkxdunTRyJEjrZiAgAAtW7ZM/fv316RJk1SuXDl98sknCgkJsWKeeuop/fXXXxo2bJiio6NVr149rVixQj4+PlbMlfoCAAAAAAAAAAAAFCZ5SvwtXLgwx3o3NzdNnTpVU6dOzTbG399fy5cvz7Gd5s2ba/fu3TnG9OnTR3369LmmvgAAAAAAAAAAAACFxTU94w8AAAAAAAAAAADAzYHEHwAAAAAAAAAAAFAIkPgDAAAAAAAAAAAACgESfwAAAAAAAAAAAEAhQOIPAAAAAAAAAAAAKARI/AEAAAAAAAAAAACFAIk/AAAAAAAAAAAAoBAg8QcAAAAAAAAAAAAUAiT+AAAAAAAAAAAAgEKAxB8AAAAAAAAAAABQCJD4AwAAuAWMHTtWDg4O6tevn1V28eJFhYeHq2TJkvLw8FCHDh0UExNjt9ypU6cUGhqqokWLqkyZMho0aJBSU1PtYtatW6cGDRrI1dVVVapU0Zw5c/JhiwAAAK6PDRs2qF27dvLz85ODg4O++eYbu3pjjIYNG6ayZcvK3d1drVq10tGjR+1izp49q7CwMNlsNnl5ealbt246f/68XczevXvVtGlTubm5qXz58ho3btyN3jQAAIA8I/EHAABwk9uxY4c++ugj1alTx668f//++v7777V48WKtX79ef/zxhx577DGrPi0tTaGhoUpOTtaWLVs0d+5czZkzR8OGDbNiTpw4odDQUN1///3as2eP+vXrp+7du2vlypX5tn0AAADX4sKFC6pbt66mTp2aZf24ceP04YcfasaMGdq2bZuKFSumkJAQXbx40YoJCwvTgQMHFBERoaVLl2rDhg3q0aOHVZ+QkKDWrVvL399fUVFReu+99zR8+HDNnDnzhm8fAABAXjgXdAcAAACQvfPnzyssLEwff/yx3n77bas8Pj5es2bN0vz589WiRQtJ0uzZs1WjRg1t3bpVjRs31qpVq3Tw4EGtXr1aPj4+qlevnkaNGqVXX31Vw4cPl4uLi2bMmKGAgACNHz9eklSjRg1t2rRJEyZMUEhISIFsMwAAQF60adNGbdq0ybLOGKOJEydq6NChat++vSTps88+k4+Pj7755ht17NhRhw4d0ooVK7Rjxw41bNhQkjR58mS1bdtW77//vvz8/DRv3jwlJyfr008/lYuLi2rWrKk9e/bogw8+sEsQAgAAFDSu+AMAALiJhYeHKzQ0VK1atbIrj4qKUkpKil159erVVaFCBUVGRkqSIiMjVbt2bfn4+FgxISEhSkhI0IEDB6yYy9sOCQmx2gAAALiVnThxQtHR0XbzHU9PTzVq1MhuzuTl5WUl/SSpVatWcnR01LZt26yYZs2aycXFxYoJCQnR4cOH9c8//+TT1gAAAFwZV/wBAADcpBYuXKhdu3Zpx44dmeqio6Pl4uIiLy8vu3IfHx9FR0dbMZcm/TLqM+pyiklISFBiYqLc3d2z7FtSUpKSkpKs9wkJCXnbOAAAgHyQMefJar5z6XyoTJkydvXOzs7y9va2iwkICMjURkZdiRIlslw/cyYAAJDfuOIPAADgJnT69Gm9/PLLmjdvntzc3Aq6O5mMGTNGnp6e1qt8+fIF3SUAAICbDnMmAACQ30j8AQAA3ISioqIUGxurBg0ayNnZWc7Ozlq/fr0+/PBDOTs7y8fHR8nJyYqLi7NbLiYmRr6+vpIkX19fxcTEZKrPqMspxmazZXu1nyQNGTJE8fHx1uv06dPXuskAAADXXcacJ6v5zqXzodjYWLv61NRUnT17Nk/zqqwwZwIAAPmNxB8AAMBNqGXLltq3b5/27NljvRo2bKiwsDDr/4sUKaI1a9ZYyxw+fFinTp1ScHCwJCk4OFj79u2zO5EVEREhm82mwMBAK+bSNjJiMtrIjqurq2w2m90LAADgZhMQECBfX1+7+U5CQoK2bdtmN2eKi4tTVFSUFbN27Vqlp6erUaNGVsyGDRuUkpJixURERKhatWrZ3uZTYs4EAADyH8/4AwAAuAkVL15ctWrVsisrVqyYSpYsaZV369ZNAwYMkLe3t2w2m/r27avg4GA1btxYktS6dWsFBgaqc+fOGjdunKKjozV06FCFh4fL1dVVktSzZ09NmTJFgwcPVteuXbV27VotWrRIy5Yty98NBgAAuErnz5/XsWPHrPcnTpzQnj175O3trQoVKqhfv356++23VbVqVQUEBOjNN9+Un5+fHnnkEUlSjRo19OCDD+qFF17QjBkzlJKSoj59+qhjx47y8/OTJD399NMaMWKEunXrpldffVX79+/XpEmTNGHChILYZAAAgGyR+AMAALhFTZgwQY6OjurQoYOSkpIUEhKiadOmWfVOTk5aunSpevXqpeDgYBUrVkxdunTRyJEjrZiAgAAtW7ZM/fv316RJk1SuXDl98sknCgkJKYhNAgAAyLOdO3fq/vvvt94PGDBAktSlSxfNmTNHgwcP1oULF9SjRw/FxcWpSZMmWrFihd1zlOfNm6c+ffqoZcuW1vzqww8/tOo9PT21atUqhYeHKygoSKVKldKwYcPUo0eP/NtQAACAXCDxBwAAcItYt26d3Xs3NzdNnTpVU6dOzXYZf39/LV++PMd2mzdvrt27d1+PLgIAAOS75s2byxiTbb2Dg4NGjhxp9+Ony3l7e2v+/Pk5rqdOnTrauHHjVfcTAAAgP/CMPwAAAAAAAAAAAKAQIPEHAAAAAAAAAAAAFAIk/gAAAAAAAAAAAIBCgMQfAAAAAAAAAAAAUAiQ+AMAAAAAAAAAAAAKARJ/AAAAAAAAAAAAQCFA4g8AAAAAAAAAAAAoBEj8AQAAAAAAAAAAAIUAiT8AAAAAAAAAAACgECDxBwAAAAAAAAAAABQCJP4AAAAAAAAAAACAQoDEHwqVsWPHysHBQf369bPKLl68qPDwcJUsWVIeHh7q0KGDYmJi7JY7deqUQkNDVbRoUZUpU0aDBg1Sampqjus6e/aswsLCZLPZ5OXlpW7duun8+fN2MXv37lXTpk3l5uam8uXLa9y4cZnaWbx4sapXry43NzfVrl1by5cvv/odAAAAAAAAAAAAblsk/lBo7NixQx999JHq1KljV96/f399//33Wrx4sdavX68//vhDjz32mFWflpam0NBQJScna8uWLZo7d67mzJmjYcOG5bi+sLAwHThwQBEREVq6dKk2bNigHj16WPUJCQlq3bq1/P39FRUVpffee0/Dhw/XzJkzrZgtW7aoU6dO6tatm3bv3q1HHnlEjzzyiPbv33+d9goAAAAAAAAAALhdkPhDoXD+/HmFhYXp448/VokSJazy+Ph4zZo1Sx988IFatGihoKAgzZ49W1u2bNHWrVslSatWrdLBgwf1xRdfqF69emrTpo1GjRqlqVOnKjk5Ocv1HTp0SCtWrNAnn3yiRo0aqUmTJpo8ebIWLlyoP/74Q5I0b948JScn69NPP1XNmjXVsWNHvfTSS/rggw+sdiZNmqQHH3xQgwYNUo0aNTRq1Cg1aNBAU6ZMuYF7CwAAAAAAAAAAFEYk/lAohIeHKzQ0VK1atbIrj4qKUkpKil159erVVaFCBUVGRkqSIiMjVbt2bfn4+FgxISEhSkhI0IEDB7JcX2RkpLy8vNSwYUOrrFWrVnJ0dNS2bdusmGbNmsnFxcWu3cOHD+uff/6xYi7vc0hIiNU3AAAAAAAAAACA3HIu6A4A12rhwoXatWuXduzYkakuOjpaLi4u8vLysiv38fFRdHS0FXNp0i+jPqMuK9HR0SpTpoxdmbOzs7y9ve3aDQgIyLbdEiVKZLvu7NYLAAAAAAAAAACQHRJ/uKWdPn1aL7/8siIiIuTm5lbQ3QEAAAAAAAAAACgw3OoTt7SoqCjFxsaqQYMGcnZ2lrOzs9avX68PP/xQzs7O8vHxUXJysuLi4uyWi4mJka+vryTJ19dXMTExmeoz6rLi6+ur2NhYu7LU1FSdPXs2T+1mF5PdegEAAAAAAAAAALJD4g+3tJYtW2rfvn3as2eP9WrYsKHCwsKs/y9SpIjWrFljLXP48GGdOnVKwcHBkqTg4GDt27fPLpEXEREhm82mwMDALNcbHBysuLg4RUVFWWVr165Venq6GjVqZMVs2LBBKSkpdu1Wq1ZNJUqUsGIu7VtGTEbfAAAAAAAAAAAAcotbfeKWVrx4cdWqVcuurFixYipZsqRV3q1bNw0YMEDe3t6y2Wzq27evgoOD1bhxY0lS69atFRgYqM6dO2vcuHGKjo7W0KFDFR4eLldX1yzXW6NGDT344IN64YUXNGPGDKWkpKhPnz7q2LGj/Pz8JElPP/20RowYoW7duunVV1/V/v37NWnSJE2YMMFq5+WXX9Z9992n8ePHKzQ0VAsXLtTOnTs1c+bMG7G7AAAAAAAAAABAIcYVfyj0JkyYoIceekgdOnRQs2bN5Ovrq6+++sqqd3Jy0tKlS+Xk5KTg4GA988wzevbZZzVy5Egr5uTJk3JwcNC6deussnnz5ql69epq2bKl2rZtqyZNmtgl7Dw9PbVq1SqdOHFCQUFBGjhwoIYNG6YePXpYMffcc4/mz5+vmTNnqm7dulqyZIm++eabTMlMAAAAAAAAAACAK+GKPxQ6lybnJMnNzU1Tp07V1KlTs13G399fy5cvz7b+xIkT8vLyUt26da0yb29vzZ8/P8e+1KlTRxs3bswx5oknntATTzyRYwwAAAAAAAAAAMCVcMUfkAvLly/X66+/bj2bDwAAAAAAAAAA4GbDFX9ALrz33nsF3QUAAAAAAAAAAIAcccUfAAAAAAAAAAAAUAiQ+AMAAAAAAAAAAAAKARJ/AAAAAAAAAAAAQCFA4g+FwpkzZ1SmTBmdPHmyoLuSZzNmzFC7du0KuhsAAAAAAAAAAOAWR+IPhcLo0aPVvn17VaxY0a78zJkzKleunBwcHBQXF2dXt27dOjVo0ECurq6qUqWK5syZc8X17N27V02bNpWbm5vKly+vcePG2dVHRETozjvvlM1mU+fOnZWcnGzVxcfH684779Svv/5qt0zXrl21a9cubdy4MU/bDAAAAAAAAAAAcCkSf7jl/fvvv5o1a5a6deuWqa5bt26qU6dOpvITJ04oNDRU999/v/bs2aN+/fqpe/fuWrlyZbbrSUhIUOvWreXv76+oqCi99957Gj58uGbOnClJSk9P19NPP62ePXsqMjJSO3futOok6bXXXlPPnj3l7+9v166Li4uefvppffjhh1e7CwAAAAAAAAAAAORc0B0ArtXy5cvl6uqqxo0b25VPnz5dcXFxGjZsmH744Qe7uhkzZiggIEDjx4+XJNWoUUObNm3ShAkTFBISkuV65s2bp+TkZH366adycXFRzZo1tWfPHn3wwQfq0aOH/v77b/3999/q3bu33Nzc9PDDD+vQoUOSpC1btmjHjh2aMmVKlm23a9dODzzwgBITE+Xu7n6tuwQAAAAAAAAAANyGuOIPt7yNGzcqKCjIruzgwYMaOXKkPvvsMzk6Zv6YR0ZGqlWrVnZlISEhioyMzHY9kZGRatasmVxcXOyWOXz4sP755x+VLl1aZcuW1apVq/Tvv/9q48aNqlOnjlJSUtSrVy999NFHcnJyyrLthg0bKjU1Vdu2bcvLpgMAAAAAAAAAAFhI/OGW9+uvv8rPz896n5SUpE6dOum9995ThQoVslwmOjpaPj4+dmU+Pj5KSEhQYmJinpbJqHNwcNCiRYs0atQo1axZU/Xr11fXrl01duxY3X///XJzc9O9996ratWqZbryr2jRovL09Mz0/D8AAAAAAAAAAIDc4lafuOUlJibKzc3Nej9kyBDVqFFDzzzzTL73pUmTJtqxY4f1/siRI/rss8+0e/duNWvWTC+//LLatGmjWrVqqVmzZnbPH3R3d9e///6b730GAAAAAAAAAACFA1f84ZZXqlQp/fPPP9b7tWvXavHixXJ2dpazs7Natmxpxb311luSJF9fX8XExNi1ExMTI5vNlu0z9rJbJqMuKy+++KLGjx+v9PR07d69W0888YTKlCmj++67T+vXr7eLPXv2rEqXLp2HLQcAAAAAAAAAAPh/XPGHW179+vX1xRdfWO//97//2d2uc8eOHeratas2btyoypUrS5KCg4O1fPlyu3YiIiIUHByc7XqCg4P1xhtvKCUlRUWKFLGWqVatmkqUKJEpftasWfL29tbDDz9sJSZTUlKs/6alpVmxv/zyiy5evKj69evndfMBAAAAAAAAAAAkXeMVf2PHjpWDg4P69etnlV28eFHh4eEqWbKkPDw81KFDh0xXSZ06dUqhoaEqWrSoypQpo0GDBik1NdUuZt26dWrQoIFcXV1VpUoVzZkzJ9P6p06dqooVK8rNzU2NGjXS9u3b7epz0xfc+kJCQnTgwAEruVa5cmXVqlXLegUEBEiSatSooTJlykiSevbsqePHj2vw4MH6+eefNW3aNC1atEj9+/e32p0yZYp1taAkPf3003JxcVG3bt104MABffnll5o0aZIGDBiQqU+xsbF6++23NXnyZElSiRIlVKNGDU2cOFGRkZFas2aN7r33Xit+48aNqlSpkpWYBAAAAAAAAAAAyKurTvzt2LFDH330kd0zyiSpf//++v7777V48WKtX79ef/zxhx577DGrPi0tTaGhoUpOTtaWLVs0d+5czZkzR8OGDbNiTpw4odDQUN1///3as2eP+vXrp+7du2vlypVWzJdffqkBAwborbfe0q5du1S3bl2FhIQoNjY2131B4VC7dm01aNBAixYtyvUyAQEBWrZsmSIiIlS3bl2NHz9en3zyiUJCQqyYv//+W7/88ov13tPTU6tWrdKJEycUFBSkgQMHatiwYerRo0em9l9++WUNHDhQfn5+VtmcOXO0cOFCPfTQQxo0aJDuuusuq27BggV64YUX8rrpAAAAAAAAAAAAFgdjjMnrQufPn1eDBg00bdo0vf3226pXr54mTpyo+Ph4lS5dWvPnz9fjjz8uSfr5559Vo0YNRUZGqnHjxvrhhx/00EMP6Y8//pCPj48kacaMGXr11Vf1119/ycXFRa+++qqWLVum/fv3W+vs2LGj4uLitGLFCklSo0aNdNddd2nKlCmSpPT0dJUvX159+/bVa6+9lqu+XElCQoI8PT0VHx8vm82W192EfLRs2TINGjRI+/fvl6PjrfXoygMHDqhFixY6cuSIPD09C7o7uIlVfG1ZQXcBKHROjg29YW3fbvOI/NhexkHg+rqRY2BBYqwArj/mTNcPcybg1lQY502MFcD1d7PMma4qQxIeHq7Q0FC1atXKrjwqKkopKSl25dWrV1eFChUUGRkpSYqMjFTt2rWtpJ/0360aExISdODAASvm8rZDQkKsNpKTkxUVFWUX4+joqFatWlkxuenL5ZKSkpSQkGD3wq0hNDRUPXr00O+//17QXcmzP//8U5999hlJPwAAAAAAAAAAcE2c87rAwoULtWvXLu3YsSNTXXR0tFxcXOTl5WVX7uPjo+joaCvm0qRfRn1GXU4xCQkJSkxM1D///KO0tLQsY37++edc9+VyY8aM0YgRI3LY+uuPX1ZcT1U1cepeSXsLuiNX50c+C9dLYfwVFgAAAAAAAAAAV5KnK/5Onz6tl19+WfPmzZObm9uN6lOBGTJkiOLj463X6dOnC7pLAAAAAAAAAAAAQK7kKfEXFRWl2NhYNWjQQM7OznJ2dtb69ev14YcfytnZWT4+PkpOTlZcXJzdcjExMfL19ZUk+fr6KiYmJlN9Rl1OMTabTe7u7ipVqpScnJyyjLm0jSv15XKurq6y2Wx2LwAAAAAAAAAAAOBWkKfEX8uWLbVv3z7t2bPHejVs2FBhYWHW/xcpUkRr1qyxljl8+LBOnTql4OBgSVJwcLD27dun2NhYKyYiIkI2m02BgYFWzKVtZMRktOHi4qKgoCC7mPT0dK1Zs8aKCQoKumJfAAAAAAAAAAAAgMIiT8/4K168uGrVqmVXVqxYMZUsWdIq79atmwYMGCBvb2/ZbDb17dtXwcHBaty4sSSpdevWCgwMVOfOnTVu3DhFR0dr6NChCg8Pl6urqySpZ8+emjJligYPHqyuXbtq7dq1WrRokZYt+/9noA0YMEBdunRRw4YNdffdd2vixIm6cOGCnn/+eUmSp6fnFfsCAAAAAAAAAAAAFBZ5SvzlxoQJE+To6KgOHTooKSlJISEhmjZtmlXv5OSkpUuXqlevXgoODlaxYsXUpUsXjRw50ooJCAjQsmXL1L9/f02aNEnlypXTJ598opCQECvmqaee0l9//aVhw4YpOjpa9erV04oVK+Tj45PrvgAAAAAAAAAAAACFxTUn/tatW2f33s3NTVOnTtXUqVOzXcbf31/Lly/Psd3mzZtr9+7dOcb06dNHffr0ybY+N30BAAAAAAAAAAAACoM8PeMPAAAAAAAAAAAAwM2JxB8AAAAAAAAAAABQCJD4AwAAAAAAAAAAAAoBEn8AAAAAAAAAAABAIUDiDwAAAAAAAAAAACgESPwBAAAAAACgUEtLS9Obb76pgIAAubu7q3Llyho1apSMMVaMMUbDhg1T2bJl5e7urlatWuno0aN27Zw9e1ZhYWGy2Wzy8vJSt27ddP78+fzeHAAAgGyR+AMAAAAAAECh9u6772r69OmaMmWKDh06pHfffVfjxo3T5MmTrZhx48bpww8/1IwZM7Rt2zYVK1ZMISEhunjxohUTFhamAwcOKCIiQkuXLtWGDRvUo0ePgtgkAACALDkXdAcAAAAAAACAG2nLli1q3769QkNDJUkVK1bUggULtH37dkn/Xe03ceJEDR06VO3bt5ckffbZZ/Lx8dE333yjjh076tChQ1qxYoV27Nihhg0bSpImT56stm3b6v3335efn1/BbBwAAMAluOIPAAAAAAAAhdo999yjNWvW6MiRI5Kkn376SZs2bVKbNm0kSSdOnFB0dLRatWplLePp6alGjRopMjJSkhQZGSkvLy8r6SdJrVq1kqOjo7Zt25aPWwMAAJA9rvgDAAAAAABAofbaa68pISFB1atXl5OTk9LS0jR69GiFhYVJkqKjoyVJPj4+dsv5+PhYddHR0SpTpoxdvbOzs7y9va2YyyUlJSkpKcl6n5CQcN22CQAAICtc8QcAAAAAAIBCbdGiRZo3b57mz5+vXbt2ae7cuXr//fc1d+7cG7reMWPGyNPT03qVL1/+hq4PAACAxB8AAAAAAAAKtUGDBum1115Tx44dVbt2bXXu3Fn9+/fXmDFjJEm+vr6SpJiYGLvlYmJirDpfX1/Fxsba1aempurs2bNWzOWGDBmi+Ph463X69OnrvWkAAAB2SPwBAAAAAACgUPv333/l6Gh/GszJyUnp6emSpICAAPn6+mrNmjVWfUJCgrZt26bg4GBJUnBwsOLi4hQVFWXFrF27Vunp6WrUqFGW63V1dZXNZrN7AQAA3Eg84w8AAAAAAACFWrt27TR69GhVqFBBNWvW1O7du/XBBx+oa9eukiQHBwf169dPb7/9tqpWraqAgAC9+eab8vPz0yOPPCJJqlGjhh588EG98MILmjFjhlJSUtSnTx917NhRfn5+Bbh1AAAA/4/EHwAAAAAAAAq1yZMn680331Tv3r0VGxsrPz8/vfjiixo2bJgVM3jwYF24cEE9evRQXFycmjRpohUrVsjNzc2KmTdvnvr06aOWLVvK0dFRHTp00IcfflgQmwQAAJAlEn8AAAAAAAAo1IoXL66JEydq4sSJ2cY4ODho5MiRGjlyZLYx3t7emj9//g3oIQAAwPXBM/4AAAAAAAAAAACAQoDEHwAAAAAAAAAAAFAIkPgDAAAAAAAAAAAACgESfwAAAAAAAAAAAEAhQOIPAAAAAAAAAAAAKARI/AEAANykpk+frjp16shms8lmsyk4OFg//PCDVX/x4kWFh4erZMmS8vDwUIcOHRQTE2PXxqlTpxQaGqqiRYuqTJkyGjRokFJTU+1i1q1bpwYNGsjV1VVVqlTRnDlz8mPzAAAAAAAAcJ2R+AMAALhJlStXTmPHjlVUVJR27typFi1aqH379jpw4IAkqX///vr++++1ePFirV+/Xn/88Ycee+wxa/m0tDSFhoYqOTlZW7Zs0dy5czVnzhwNGzbMijlx4oRCQ0N1//33a8+ePerXr5+6d++ulStX5vv2AgAAAAAA4No4F3QHAAAAkLV27drZvR89erSmT5+urVu3qly5cpo1a5bmz5+vFi1aSJJmz56tGjVqaOvWrWrcuLFWrVqlgwcPavXq1fLx8VG9evU0atQovfrqqxo+fLhcXFw0Y8YMBQQEaPz48ZKkGjVqaNOmTZowYYJCQkLyfZsBAAAAAABw9bjiDwAA4BaQlpamhQsX6sKFCwoODlZUVJRSUlLUqlUrK6Z69eqqUKGCIiMjJUmRkZGqXbu2fHx8rJiQkBAlJCRYVw1GRkbatZERk9EGAAAAAAAAbh1c8QcAAHAT27dvn4KDg3Xx4kV5eHjo66+/VmBgoPbs2SMXFxd5eXnZxfv4+Cg6OlqSFB0dbZf0y6jPqMspJiEhQYmJiXJ3d8+yX0lJSUpKSrLeJyQkXNN2AgAAAAAA4NpxxR8AAMBNrFq1atqzZ4+2bdumXr16qUuXLjp48GBBd0tjxoyRp6en9SpfvnxBdwkAAAAAAOC2R+IPAADgJubi4qIqVaooKChIY8aMUd26dTVp0iT5+voqOTlZcXFxdvExMTHy9fWVJPn6+iomJiZTfUZdTjE2my3bq/0kaciQIYqPj7dep0+fvtZNBQAAAAAAwDUi8QcAAHALSU9PV1JSkoKCglSkSBGtWbPGqjt8+LBOnTql4OBgSVJwcLD27dun2NhYKyYiIkI2m02BgYFWzKVtZMRktJEdV1dX2Ww2uxcAAAAAAAAKFs/4AwAAuEkNGTJEbdq0UYUKFXTu3DnNnz9f69at08qVK+Xp6alu3bppwIAB8vb2ls1mU9++fRUcHKzGjRtLklq3bq3AwEB17txZ48aNU3R0tIYOHarw8HC5urpKknr27KkpU6Zo8ODB6tq1q9auXatFixZp2bJlBbnpAAAAAAAAuAok/gAAAG5SsbGxevbZZ/Xnn3/K09NTderU0cqVK/XAAw9IkiZMmCBHR0d16NBBSUlJCgkJ0bRp06zlnZyctHTpUvXq1UvBwcEqVqyYunTpopEjR1oxAQEBWrZsmfr3769JkyapXLly+uSTTxQSEpLv2wsAAAAAAIBrQ+IPAADgJjVr1qwc693c3DR16lRNnTo12xh/f38tX748x3aaN2+u3bt3X1UfAQAAAAAAcPPgGX8AAAAAAAAAAABAIUDiDwAAAAAAAAAAACgESPwBAAAAAAAAAAAAhQCJPwAAAAAAAAAAAKAQIPEHAAAAAAAAAAAAFAIk/gAAAAAAAAAAAIBCgMQfAAAAAAAAAAAAUAiQ+AMAAAAAAAAAAAAKARJ/AAAAAAAAAAAAQCFA4g8AAAAAAAAAAAAoBEj8AQAAAAAAAAAAAIUAiT8AAAAAAAAAAACgECDxBwAAAAAAAAAAABQCJP4AAAAAAAAAAACAQoDEHwAAAAAAAAAAAFAIkPgDAAAAAAAAAAAACgESfwAAAAAAAAAAAEAhQOIPAAAAAAAAAAAAKARI/AEAAAAAAAAAAACFAIk/AAAAAAAAAAAAoBAg8QcAAAAAAAAAAAAUAiT+AAAAAAAAAAAAgEKAxB8AAAAAAAAAAABQCJD4AwAAAAAAAAAAAAqBPCX+pk+frjp16shms8lmsyk4OFg//PCDVX/x4kWFh4erZMmS8vDwUIcOHRQTE2PXxqlTpxQaGqqiRYuqTJkyGjRokFJTU+1i1q1bpwYNGsjV1VVVqlTRnDlzMvVl6tSpqlixotzc3NSoUSNt377drj43fQEAAAAAAAAAAAAKizwl/sqVK6exY8cqKipKO3fuVIsWLdS+fXsdOHBAktS/f399//33Wrx4sdavX68//vhDjz32mLV8WlqaQkNDlZycrC1btmju3LmaM2eOhg0bZsWcOHFCoaGhuv/++7Vnzx7169dP3bt318qVK62YL7/8UgMGDNBbb72lXbt2qW7dugoJCVFsbKwVc6W+AAAAAAAAAAAAAIVJnhJ/7dq1U9u2bVW1alXdeeedGj16tDw8PLR161bFx8dr1qxZ+uCDD9SiRQsFBQVp9uzZ2rJli7Zu3SpJWrVqlQ4ePKgvvvhC9erVU5s2bTRq1ChNnTpVycnJkqQZM2YoICBA48ePV40aNdSnTx89/vjjmjBhgtWPDz74QC+88IKef/55BQYGasaMGSpatKg+/fRTScpVXwAAAAAAAAAAAIDC5Kqf8ZeWlqaFCxfqwoULCg4OVlRUlFJSUtSqVSsrpnr16qpQoYIiIyMlSZGRkapdu7Z8fHysmJCQECUkJFhXDUZGRtq1kRGT0UZycrKioqLsYhwdHdWqVSsrJjd9yUpSUpISEhLsXgAAAAAAAAAAAMCtIM+Jv3379snDw0Ourq7q2bOnvv76awUGBio6OlouLi7y8vKyi/fx8VF0dLQkKTo62i7pl1GfUZdTTEJCghITE/X3338rLS0ty5hL27hSX7IyZswYeXp6Wq/y5cvnbqcAAAAAAAAAAAAABSzPib9q1appz5492rZtm3r16qUuXbro4MGDN6Jv+W7IkCGKj4+3XqdPny7oLgEAAAAAAAAAAAC54pzXBVxcXFSlShVJUlBQkHbs2KFJkybpqaeeUnJysuLi4uyutIuJiZGvr68kydfXV9u3b7drLyYmxqrL+G9G2aUxNptN7u7ucnJykpOTU5Yxl7Zxpb5kxdXVVa6urnnYGwAAAAAAAAAAAMDN4aqf8ZchPT1dSUlJCgoKUpEiRbRmzRqr7vDhwzp16pSCg4MlScHBwdq3b59iY2OtmIiICNlsNgUGBloxl7aREZPRhouLi4KCguxi0tPTtWbNGismN30BAAAAAAAAAAAACpM8XfE3ZMgQtWnTRhUqVNC5c+c0f/58rVu3TitXrpSnp6e6deumAQMGyNvbWzabTX379lVwcLAaN24sSWrdurUCAwPVuXNnjRs3TtHR0Ro6dKjCw8OtK+169uypKVOmaPDgweratavWrl2rRYsWadmyZVY/BgwYoC5duqhhw4a6++67NXHiRF24cEHPP/+8JOWqLwAAAAAAAAAAAEBhkqfEX2xsrJ599ln9+eef8vT0VJ06dbRy5Uo98MADkqQJEybI0dFRHTp0UFJSkkJCQjRt2jRreScnJy1dulS9evVScHCwihUrpi5dumjkyJFWTEBAgJYtW6b+/ftr0qRJKleunD755BOFhIRYMU899ZT++usvDRs2TNHR0apXr55WrFghHx8fK+ZKfQEAAAAAAAAAAAAKkzwl/mbNmpVjvZubm6ZOnaqpU6dmG+Pv76/ly5fn2E7z5s21e/fuHGP69OmjPn36XFNfAAAAAAAAAAAAgMLimp/xBwAAAAAAAAAAAKDgkfgDAAAAAAAAAAAACgESfwAAAAAAACj0fv/9dz3zzDMqWbKk3N3dVbt2be3cudOqN8Zo2LBhKlu2rNzd3dWqVSsdPXrUro2zZ88qLCxMNptNXl5e6tatm86fP5/fmwIAAJAtEn8AAAAAAAAo1P7555//a+/+g7Qs6/2Bv/khCyK7iMauHNH2HC0hFRUMN9NQOayETSRjWeSvSE6eXQuYo8UZQkWPW+RPjCRLQQtG8kxqgZEICSGIusZRUcmKc2CmdjnnGLtJ8Uv2+8cZnq+bIJDAwuPrNXPP7HNdn+e+r8sZ7/mMb+/nzplnnplDDjkkP/vZz/Lyyy/n1ltvzeGHH16omTx5cqZMmZJp06Zl+fLl6dq1a6qrq7Nx48ZCzciRI7Ny5crMnz8/c+bMyeLFizN69Oi22BIAwA51bOsFAAAAAMC+9M1vfjO9e/fO9OnTC2OVlZWFv1taWnLHHXdkwoQJ+eQnP5kkeeCBB1JeXp5HHnkkF198cV555ZXMmzcvzz77bAYMGJAkueuuu/Lxj388t9xyS3r16rV/NwUAsAOe+AMAAACgqP3kJz/JgAEDctFFF6Vnz5459dRT873vfa8wv3r16jQ0NGTw4MGFsbKysgwcODDLli1Lkixbtizdu3cvhH5JMnjw4LRv3z7Lly/f4XU3bdqU5ubmVgcAwL4k+AMAAACgqP3ud7/L3XffneOPPz4///nPc9VVV+XLX/5y7r///iRJQ0NDkqS8vLzV98rLywtzDQ0N6dmzZ6v5jh07pkePHoWav1ZXV5eysrLC0bt37729NQCAVgR/AAAAABS1bdu25bTTTsvNN9+cU089NaNHj86VV16ZadOm7dPrjh8/Pk1NTYVj7dq1+/R6AACCPwAAAACK2lFHHZW+ffu2GuvTp0/WrFmTJKmoqEiSNDY2tqppbGwszFVUVGTdunWt5rdu3ZrXX3+9UPPXSkpKUlpa2uoAANiXBH8AAAAAFLUzzzwzq1atajX261//Oscee2ySpLKyMhUVFVmwYEFhvrm5OcuXL09VVVWSpKqqKuvXr099fX2hZuHChdm2bVsGDhy4H3YBALBrHdt6AQAAAACwL40dOzYf+chHcvPNN+fTn/50nnnmmdxzzz255557kiTt2rXLmDFjctNNN+X4449PZWVlvv71r6dXr14ZPnx4kv97QvD8888v/EToli1bUltbm4svvji9evVqw90BAPx/gj8AAAAAitrpp5+ehx9+OOPHj8+kSZNSWVmZO+64IyNHjizUXHvttdmwYUNGjx6d9evX56Mf/WjmzZuXzp07F2pmzpyZ2tranHfeeWnfvn1GjBiRKVOmtMWWAAB2SPAHAAAAQNG74IILcsEFF+x0vl27dpk0aVImTZq005oePXpk1qxZ+2J5AAB7hXf8AQAAAAAAQBEQ/AEAAAAAAEAREPwBAAAAAABAERD8AQAAAAAAQBEQ/AEAAAAAAEAREPwBAAAAAABAERD8AQAAAAAAQBEQ/AEAAAAAAEAREPwBAAAAAABAERD8AQAAAAAAQBEQ/AEAAAAAAEAREPwBAAAAAABAERD8AQAAAAAAQBEQ/AEAAAAAAEAREPwBAAAAAABAERD8AQAAAAAAQBEQ/AEAAAAAAEAREPwBAAAAAABAERD8AQAAAAAAQBEQ/AEAAAAAAEAREPwBAByg6urqcvrpp6dbt27p2bNnhg8fnlWrVrWq2bhxY2pqanLEEUfksMMOy4gRI9LY2NiqZs2aNRk2bFgOPfTQ9OzZM9dcc022bt3aqubJJ5/MaaedlpKSkhx33HGZMWPGvt4eAAAAAHuZ4A8A4AC1aNGi1NTU5Omnn878+fOzZcuWDBkyJBs2bCjUjB07Nj/96U/z0EMPZdGiRfn973+fCy+8sDD/5ptvZtiwYdm8eXOWLl2a+++/PzNmzMjEiRMLNatXr86wYcNyzjnnZMWKFRkzZky++MUv5uc///l+3S8AAAAA707Htl4AAAA7Nm/evFafZ8yYkZ49e6a+vj5nn312mpqacu+992bWrFk599xzkyTTp09Pnz598vTTT+eMM87I448/npdffjlPPPFEysvLc8opp+TGG2/MV7/61Vx//fXp1KlTpk2blsrKytx6661Jkj59+mTJkiW5/fbbU11dvd/3DQAAAMDfxhN/AAAHiaampiRJjx49kiT19fXZsmVLBg8eXKg54YQTcswxx2TZsmVJkmXLluWkk05KeXl5oaa6ujrNzc1ZuXJloeat59hes/0cAAAAABwcPPEHAHAQ2LZtW8aMGZMzzzwzJ554YpKkoaEhnTp1Svfu3VvVlpeXp6GhoVDz1tBv+/z2uXeqaW5uzl/+8pd06dLlbevZtGlTNm3aVPjc3Nz87jYIAAAAwLvmiT8AgINATU1NXnrppTz44INtvZQkSV1dXcrKygpH796923pJAAAAAO95gj8AgANcbW1t5syZk1/84hc5+uijC+MVFRXZvHlz1q9f36q+sbExFRUVhZrGxsa3zW+fe6ea0tLSHT7tlyTjx49PU1NT4Vi7du272iMAAAAA757gDwDgANXS0pLa2to8/PDDWbhwYSorK1vN9+/fP4ccckgWLFhQGFu1alXWrFmTqqqqJElVVVVefPHFrFu3rlAzf/78lJaWpm/fvoWat55je832c+xISUlJSktLWx0AAAAAtC3v+AMAOEDV1NRk1qxZefTRR9OtW7fCO/nKysrSpUuXlJWVZdSoURk3blx69OiR0tLSXH311amqqsoZZ5yRJBkyZEj69u2bSy65JJMnT05DQ0MmTJiQmpqalJSUJEm+9KUv5dvf/nauvfbafOELX8jChQvzox/9KHPnzm2zvQMAAACw5zzxBwBwgLr77rvT1NSUQYMG5aijjiocs2fPLtTcfvvtueCCCzJixIicffbZqaioyI9//OPCfIcOHTJnzpx06NAhVVVV+fznP59LL700kyZNKtRUVlZm7ty5mT9/fvr165dbb7013//+91NdXb1f9wsAAADAu+OJPwCAA1RLS8suazp37pypU6dm6tSpO6059thj89hjj73jeQYNGpRf/epXe7xGAAAAAA4cnvgDAAAAAACAIiD4AwAAAAAAgCIg+AMAAAAAAIAiIPgDAAAAAACAIiD4AwAAAAAAgCIg+AMAAAAAAIAiIPgDAAAAAACAIiD4AwAAAAAAgCIg+AMAAAAAAIAiIPgDAAAAAACAIiD4AwAAAAAAgCIg+AMAAAAAAIAisEfBX11dXU4//fR069YtPXv2zPDhw7Nq1apWNRs3bkxNTU2OOOKIHHbYYRkxYkQaGxtb1axZsybDhg3LoYcemp49e+aaa67J1q1bW9U8+eSTOe2001JSUpLjjjsuM2bMeNt6pk6dmve///3p3LlzBg4cmGeeeWaP1wIAAAAAAADFYI+Cv0WLFqWmpiZPP/105s+fny1btmTIkCHZsGFDoWbs2LH56U9/moceeiiLFi3K73//+1x44YWF+TfffDPDhg3L5s2bs3Tp0tx///2ZMWNGJk6cWKhZvXp1hg0blnPOOScrVqzImDFj8sUvfjE///nPCzWzZ8/OuHHjct111+X5559Pv379Ul1dnXXr1u32WgAAAAAAAKBYdNyT4nnz5rX6PGPGjPTs2TP19fU5++yz09TUlHvvvTezZs3KueeemySZPn16+vTpk6effjpnnHFGHn/88bz88st54oknUl5enlNOOSU33nhjvvrVr+b6669Pp06dMm3atFRWVubWW29NkvTp0ydLlizJ7bffnurq6iTJbbfdliuvvDJXXHFFkmTatGmZO3du7rvvvnzta1/brbUAAAAAAABAsXhX7/hrampKkvTo0SNJUl9fny1btmTw4MGFmhNOOCHHHHNMli1bliRZtmxZTjrppJSXlxdqqqur09zcnJUrVxZq3nqO7TXbz7F58+bU19e3qmnfvn0GDx5cqNmdtQAAAAAAAECx2KMn/t5q27ZtGTNmTM4888yceOKJSZKGhoZ06tQp3bt3b1VbXl6ehoaGQs1bQ7/t89vn3qmmubk5f/nLX/LHP/4xb7755g5rXn311d1ey1/btGlTNm3aVPjc3Ny8q38MAAAAAAAAcED4m5/4q6mpyUsvvZQHH3xwb66nTdXV1aWsrKxw9O7du62XBAAAAAAAALvlbwr+amtrM2fOnPziF7/I0UcfXRivqKjI5s2bs379+lb1jY2NqaioKNQ0Nja+bX773DvVlJaWpkuXLjnyyCPToUOHHda89Ry7WstfGz9+fJqamgrH2rVrd+OfBgAAAAAAALS9PQr+WlpaUltbm4cffjgLFy5MZWVlq/n+/fvnkEMOyYIFCwpjq1atypo1a1JVVZUkqaqqyosvvph169YVaubPn5/S0tL07du3UPPWc2yv2X6OTp06pX///q1qtm3blgULFhRqdmctf62kpCSlpaWtDgAAAAAAADgY7NE7/mpqajJr1qw8+uij6datW+FdeWVlZenSpUvKysoyatSojBs3Lj169EhpaWmuvvrqVFVV5YwzzkiSDBkyJH379s0ll1ySyZMnp6GhIRMmTEhNTU1KSkqSJF/60pfy7W9/O9dee22+8IUvZOHChfnRj36UuXPnFtYybty4XHbZZRkwYEA+/OEP54477siGDRtyxRVXFNa0q7UAAAAAAABAsdijJ/7uvvvuNDU1ZdCgQTnqqKMKx+zZsws1t99+ey644IKMGDEiZ599dioqKvLjH/+4MN+hQ4fMmTMnHTp0SFVVVT7/+c/n0ksvzaRJkwo1lZWVmTt3bubPn59+/frl1ltvzfe///1UV1cXaj7zmc/klltuycSJE3PKKadkxYoVmTdvXsrLy3d7LQAAAAC8t3zjG99Iu3btMmbMmMLYxo0bU1NTkyOOOCKHHXZYRowY8bZXzKxZsybDhg3LoYcemp49e+aaa67J1q1b9/PqAQDe2R498dfS0rLLms6dO2fq1KmZOnXqTmuOPfbYPPbYY+94nkGDBuVXv/rVO9bU1tamtrb2Xa0FAAAAgPeGZ599Nt/97ndz8skntxofO3Zs5s6dm4ceeihlZWWpra3NhRdemKeeeipJ8uabb2bYsGGpqKjI0qVL84c//CGXXnppDjnkkNx8881tsRUAgB3aoyf+AAAAAOBg9MYbb2TkyJH53ve+l8MPP7ww3tTUlHvvvTe33XZbzj333PTv3z/Tp0/P0qVL8/TTTydJHn/88bz88sv54Q9/mFNOOSVDhw7NjTfemKlTp2bz5s1ttSUAgLcR/AEAAABQ9GpqajJs2LAMHjy41Xh9fX22bNnSavyEE07IMccck2XLliVJli1blpNOOqnVK2aqq6vT3NyclStX7vSamzZtSnNzc6sDAGBf2qOf+gQAAACAg82DDz6Y559/Ps8+++zb5hoaGtKpU6d079691Xh5eXkaGhoKNW8N/bbPb5/bmbq6utxwww3vcvUAALvPE38AAAAAFK21a9fmK1/5SmbOnJnOnTvv12uPHz8+TU1NhWPt2rX79foAwHuP4A8AAACAolVfX59169bltNNOS8eOHdOxY8csWrQoU6ZMSceOHVNeXp7Nmzdn/fr1rb7X2NiYioqKJElFRUUaGxvfNr99bmdKSkpSWlra6gAA2JcEfwAAAAAUrfPOOy8vvvhiVqxYUTgGDBiQkSNHFv4+5JBDsmDBgsJ3Vq1alTVr1qSqqipJUlVVlRdffDHr1q0r1MyfPz+lpaXp27fvft8TAMDOeMcfAAAAAEWrW7duOfHEE1uNde3aNUcccURhfNSoURk3blx69OiR0tLSXH311amqqsoZZ5yRJBkyZEj69u2bSy65JJMnT05DQ0MmTJiQmpqalJSU7Pc9AQDsjOAPAAAAgPe022+/Pe3bt8+IESOyadOmVFdX5zvf+U5hvkOHDpkzZ06uuuqqVFVVpWvXrrnssssyadKkNlw1AMDbCf4AAAAAeE958sknW33u3Llzpk6dmqlTp+70O8cee2wee+yxfbwyAIB3xzv+AAAAAAAAoAgI/gAAAAAAAKAICP4AAAAAAACgCAj+AAAAAAAAoAgI/gAAAAAAAKAICP4AAAAAAACgCAj+AAAAAAAAoAgI/gAAAAAAAKAICP4AAAAAAACgCAj+AAAAAAAAoAgI/gAAAAAAAKAICP4AAAAAAACgCAj+AAAAAAAAoAgI/gAAAAAAAKAICP4AAAAAAACgCAj+AAAAAAAAoAgI/gAAAAAAAKAICP4AAAAAAACgCAj+AAAAAAAAoAgI/gAAAAAAAKAICP4AAAAAAACgCAj+AAAAAAAAoAgI/gAAAAAAAKAICP4AAAAAAACgCAj+AAAAAAAAoAgI/gAAAAAAAKAICP4AAAAAAACgCAj+AAAAAAAAoAgI/gAAAAAAAKAICP4AAAAAAACgCAj+AAAAAAAAoAgI/gAAAAAAAKAICP4AAAAAAACgCAj+AAAAAAAAoAgI/gAAAAAAAKAICP4AAAAAAACgCAj+AAAOUIsXL84nPvGJ9OrVK+3atcsjjzzSar6lpSUTJ07MUUcdlS5dumTw4MF57bXXWtW8/vrrGTlyZEpLS9O9e/eMGjUqb7zxRquaF154IWeddVY6d+6c3r17Z/Lkyft6awAAAADsA4I/AIAD1IYNG9KvX79MnTp1h/OTJ0/OlClTMm3atCxfvjxdu3ZNdXV1Nm7cWKgZOXJkVq5cmfnz52fOnDlZvHhxRo8eXZhvbm7OkCFDcuyxx6a+vj7f+ta3cv311+eee+7Z5/sDAAAAYO/q2NYLAABgx4YOHZqhQ4fucK6lpSV33HFHJkyYkE9+8pNJkgceeCDl5eV55JFHcvHFF+eVV17JvHnz8uyzz2bAgAFJkrvuuisf//jHc8stt6RXr16ZOXNmNm/enPvuuy+dOnXKhz70oaxYsSK33XZbq4AQAAAAgAOfJ/4AAA5Cq1evTkNDQwYPHlwYKysry8CBA7Ns2bIkybJly9K9e/dC6JckgwcPTvv27bN8+fJCzdlnn51OnToVaqqrq7Nq1ar88Y9/3On1N23alObm5lYHAAAAAG1L8AcAcBBqaGhIkpSXl7caLy8vL8w1NDSkZ8+ereY7duyYHj16tKrZ0Tneeo0dqaurS1lZWeHo3bv3u9sQAAAAAO+a4A8AgD02fvz4NDU1FY61a9e29ZIAAAAA3vMEfwAAB6GKiookSWNjY6vxxsbGwlxFRUXWrVvXan7r1q15/fXXW9Xs6BxvvcaOlJSUpLS0tNUBAAAAQNsS/AEAHIQqKytTUVGRBQsWFMaam5uzfPnyVFVVJUmqqqqyfv361NfXF2oWLlyYbdu2ZeDAgYWaxYsXZ8uWLYWa+fPn54Mf/GAOP/zw/bQbAAAAAPYGwR8AwAHqjTfeyIoVK7JixYokyerVq7NixYqsWbMm7dq1y5gxY3LTTTflJz/5SV588cVceuml6dWrV4YPH54k6dOnT84///xceeWVeeaZZ/LUU0+ltrY2F198cXr16pUk+dznPpdOnTpl1KhRWblyZWbPnp0777wz48aNa6NdAwAAAPC36tjWCwAAYMeee+65nHPOOYXP28O4yy67LDNmzMi1116bDRs2ZPTo0Vm/fn0++tGPZt68eencuXPhOzNnzkxtbW3OO++8tG/fPiNGjMiUKVMK82VlZXn88cdTU1OT/v3758gjj8zEiRMzevTo/bdRAAAAAPYKwR8AwAFq0KBBaWlp2el8u3btMmnSpEyaNGmnNT169MisWbPe8Tonn3xyfvnLX/7N6wQAAADgwLDHP/W5ePHifOITn0ivXr3Srl27PPLII63mW1paMnHixBx11FHp0qVLBg8enNdee61Vzeuvv56RI0emtLQ03bt3z6hRo/LGG2+0qnnhhRdy1llnpXPnzundu3cmT578trU89NBDOeGEE9K5c+ecdNJJeeyxx/Z4LQAAAAAAAFAM9jj427BhQ/r165epU6fucH7y5MmZMmVKpk2bluXLl6dr166prq7Oxo0bCzUjR47MypUrM3/+/MyZMyeLFy9u9XNSzc3NGTJkSI499tjU19fnW9/6Vq6//vrcc889hZqlS5fms5/9bEaNGpVf/epXGT58eIYPH56XXnppj9YCAAAAAAAAxWCPf+pz6NChGTp06A7nWlpacscdd2TChAn55Cc/mSR54IEHUl5enkceeSQXX3xxXnnllcybNy/PPvtsBgwYkCS566678vGPfzy33HJLevXqlZkzZ2bz5s2577770qlTp3zoQx/KihUrcttttxUCwjvvvDPnn39+rrnmmiTJjTfemPnz5+fb3/52pk2btltrAQAAAAAAgGKxx0/8vZPVq1enoaEhgwcPLoyVlZVl4MCBWbZsWZJk2bJl6d69eyH0S5LBgwenffv2Wb58eaHm7LPPTqdOnQo11dXVWbVqVf74xz8Wat56ne0126+zO2sBAAAAAACAYrHHT/y9k4aGhiRJeXl5q/Hy8vLCXENDQ3r27Nl6ER07pkePHq1qKisr33aO7XOHH354GhoadnmdXa3lr23atCmbNm0qfG5ubt7FjgEAAAAAAODAsFef+DvY1dXVpaysrHD07t27rZcEAAAAwLtUV1eX008/Pd26dUvPnj0zfPjwrFq1qlXNxo0bU1NTkyOOOCKHHXZYRowYkcbGxlY1a9asybBhw3LooYemZ8+eueaaa7J169b9uRUAgHe0V4O/ioqKJHlbU9TY2FiYq6ioyLp161rNb926Na+//nqrmh2d463X2FnNW+d3tZa/Nn78+DQ1NRWOtWvX7sauAQAAADiQLVq0KDU1NXn66aczf/78bNmyJUOGDMmGDRsKNWPHjs1Pf/rTPPTQQ1m0aFF+//vf58ILLyzMv/nmmxk2bFg2b96cpUuX5v7778+MGTMyceLEttgSAMAO7dXgr7KyMhUVFVmwYEFhrLm5OcuXL09VVVWSpKqqKuvXr099fX2hZuHChdm2bVsGDhxYqFm8eHG2bNlSqJk/f34++MEP5vDDDy/UvPU622u2X2d31vLXSkpKUlpa2uoAAAAA4OA2b968XH755fnQhz6Ufv36ZcaMGVmzZk3hv081NTXl3nvvzW233ZZzzz03/fv3z/Tp07N06dI8/fTTSZLHH388L7/8cn74wx/mlFNOydChQ3PjjTdm6tSp2bx5c1tuDwCgYI+DvzfeeCMrVqzIihUrkiSrV6/OihUrsmbNmrRr1y5jxozJTTfdlJ/85Cd58cUXc+mll6ZXr14ZPnx4kqRPnz45//zzc+WVV+aZZ57JU089ldra2lx88cXp1atXkuRzn/tcOnXqlFGjRmXlypWZPXt27rzzzowbN66wjq985SuZN29ebr311rz66qu5/vrr89xzz6W2tjZJdmstAAAAALz3NDU1JUl69OiRJKmvr8+WLVsyePDgQs0JJ5yQY445JsuWLUuSLFu2LCeddFLKy8sLNdXV1Wlubs7KlSt3eJ1Nmzalubm51QEAsC913NMvPPfccznnnHMKn7eHcZdddllmzJiRa6+9Nhs2bMjo0aOzfv36fPSjH828efPSuXPnwndmzpyZ2tranHfeeWnfvn1GjBiRKVOmFObLysry+OOPp6amJv3798+RRx6ZiRMnZvTo0YWaj3zkI5k1a1YmTJiQf/3Xf83xxx+fRx55JCeeeGKhZnfWAgAAAMB7x7Zt2zJmzJiceeaZhf+O1NDQkE6dOqV79+6tasvLy9PQ0FCoeWvot31++9yO1NXV5YYbbtjLOwAA2Lk9Dv4GDRqUlpaWnc63a9cukyZNyqRJk3Za06NHj8yaNesdr3PyySfnl7/85TvWXHTRRbnooove1VoAAAAAeO+oqanJSy+9lCVLluzza40fP77VL1g1Nzend+/e+/y6AMB71x4HfwAAAABwMKqtrc2cOXOyePHiHH300YXxioqKbN68OevXr2/11F9jY2MqKioKNc8880yr8zU2NhbmdqSkpCQlJSV7eRcAADu3x+/4AwAAAICDSUtLS2pra/Pwww9n4cKFqaysbDXfv3//HHLIIVmwYEFhbNWqVVmzZk2qqqqSJFVVVXnxxRezbt26Qs38+fNTWlqavn377p+NAADsgif+AAAAAChqNTU1mTVrVh599NF069at8E6+srKydOnSJWVlZRk1alTGjRuXHj16pLS0NFdffXWqqqpyxhlnJEmGDBmSvn375pJLLsnkyZPT0NCQCRMmpKamxlN9AMABQ/AHAAAAQFG7++67kySDBg1qNT59+vRcfvnlSZLbb7897du3z4gRI7Jp06ZUV1fnO9/5TqG2Q4cOmTNnTq666qpUVVWla9euueyyyzJp0qT9tQ0AgF0S/AEAAABQ1FpaWnZZ07lz50ydOjVTp07dac2xxx6bxx57bG8uDQBgr/KOPwAAAAAAACgCgj8AAAAAAAAoAoI/AAAAAAAAKAKCPwAAAAAAACgCgj8AAAAAAAAoAoI/AAAAAAAAKAKCPwAAAAAAACgCgj8AAAAAAAAoAoI/AAAAAAAAKAKCPwAAAAAAACgCgj8AAAAAAAAoAoI/AAAAAAAAKAKCPwAAAAAAACgCgj8AAAAAAAAoAoI/AAAAAAAAKAKCPwAAAAAAACgCgj8AAAAAAAAoAoI/AAAAAAAAKAKCPwAAAAAAACgCgj8AAAAAAAAoAoI/AAAAAAAAKAKCPwAAAAAAACgCgj8AAAAAAAAoAoI/AAAAAAAAKAKCPwAAAAAAACgCgj8AAAAAAAAoAoI/AAAAAAAAKAKCPwAAAAAAACgCgj8AAAAAAAAoAoI/AAAAAAAAKAKCPwAAAAAAACgCgj8AAAAAAAAoAoI/AAAAAAAAKAKCPwAAAAAAACgCgj8AAAAAAAAoAoI/AAAAAAAAKAKCPwAAAAAAACgCgj8AAAAAAAAoAoI/AAAAAAAAKAKCPwAAAAAAACgCgj8AAAAAAAAoAoI/AAAAAAAAKAKCPwAAAAAAACgCgj8AAAAAAAAoAoI/AAAAAAAAKAKCPwAAAAAAACgCgj8AAAAAAAAoAoI/AAAAAAAAKAKCPwAAAAAAACgCgj8AAAAAAAAoAoI/AAAAAAAAKAKCPwAAAAAAACgC74ngb+rUqXn/+9+fzp07Z+DAgXnmmWfaekkAAAccPRMAwK7pmQCAA1nRB3+zZ8/OuHHjct111+X5559Pv379Ul1dnXXr1rX10gAADhh6JgCAXdMzAQAHuqIP/m677bZceeWVueKKK9K3b99MmzYthx56aO677762XhoAwAFDzwQAsGt6JgDgQNexrRewL23evDn19fUZP358Yax9+/YZPHhwli1b9rb6TZs2ZdOmTYXPTU1NSZLm5uZ9tsZtm/68z84N71X78t/ZtuR+AXvfvrxfbD93S0vLPrvG3rKnPVOib4JioGcCdpee6f/omeC9qxj7JvcK2PsOlJ6pqIO///mf/8mbb76Z8vLyVuPl5eV59dVX31ZfV1eXG2644W3jvXv33mdrBPa+sjvaegXAwWJ/3C/+9Kc/paysbN9f6F3Y054p0TdBMdAzAbtLz/R/9Ezw3qVvAnbHgdIzFXXwt6fGjx+fcePGFT5v27Ytr7/+eo444oi0a9euDVdGW2tubk7v3r2zdu3alJaWtvVygAOY+wXbtbS05E9/+lN69erV1kvZJ/RN7Iz7ILA73CvYTs/Ee5X7ILA73CvYbk96pqIO/o488sh06NAhjY2NrcYbGxtTUVHxtvqSkpKUlJS0Guvevfu+XCIHmdLSUjdYYLe4X5DkgP+/1rfb054p0Texa+6DwO5wryDRM/He5j4I7A73CpLd75na7+N1tKlOnTqlf//+WbBgQWFs27ZtWbBgQaqqqtpwZQAABw49EwDArumZAICDQVE/8Zck48aNy2WXXZYBAwbkwx/+cO64445s2LAhV1xxRVsvDQDggKFnAgDYNT0TAHCgK/rg7zOf+Uz++7//OxMnTkxDQ0NOOeWUzJs3720vYoZ3UlJSkuuuu+5tP88B8NfcLzhY6ZnYW9wHgd3hXsHBSs/E3uI+COwO9wr+Fu1aWlpa2noRAAAAAAAAwLtT1O/4AwAAAAAAgPcKwR8AAAAAAAAUAcEfAAAAAAAAFAHBHwDsJTNmzEj37t3behkAAAc0PRMAwK7pmfhbCf54z2nXrt07Htdff31bLxFoY5dffvkO7w+/+c1v2nppAPuNngnYFT0TgJ4J2DU9E/tbx7ZeAOxvf/jDHwp/z549OxMnTsyqVasKY4cddljh75aWlrz55pvp2NG/KvBec/7552f69Omtxt73vve10WoA9j89E7A79EzAe52eCdgdeib2J0/88Z5TUVFROMrKytKuXbvC51dffTXdunXLz372s/Tv3z8lJSVZsmRJLr/88gwfPrzVecaMGZNBgwYVPm/bti11dXWprKxMly5d0q9fv/z7v//7/t0csNeUlJS0ul9UVFTkzjvvzEknnZSuXbumd+/e+ed//ue88cYbOz3Hf/zHf+Scc85Jt27dUlpamv79++e5554rzC9ZsiRnnXVWunTpkt69e+fLX/5yNmzYsD+2B7BLeiZgd+iZgPc6PROwO/RM7E+CP9iBr33ta/nGN76RV155JSeffPJufaeuri4PPPBApk2blpUrV2bs2LH5/Oc/n0WLFu3j1QL7S/v27TNlypSsXLky999/fxYuXJhrr712p/UjR47M0UcfnWeffTb19fX52te+lkMOOSRJ8tvf/jbnn39+RowYkRdeeCGzZ8/OkiVLUltbu7+2A/Cu6ZmAHdEzAbSmZwJ2RM/EvuK5ctiBSZMm5R//8R93u37Tpk25+eab88QTT6SqqipJ8vd///dZsmRJvvvd7+ZjH/vYvloqsI/MmTOn1U+yDB06NA899FDh8/vf//7cdNNN+dKXvpTvfOc7OzzHmjVrcs011+SEE05Ikhx//PGFubq6uowcOTJjxowpzE2ZMiUf+9jHcvfdd6dz5877YFcAe5eeCdAzAeyangnQM7E/Cf5gBwYMGLBH9b/5zW/y5z//+W1N3ObNm3PqqafuzaUB+8k555yTu+++u/C5a9eueeKJJ1JXV5dXX301zc3N2bp1azZu3Jg///nPOfTQQ992jnHjxuWLX/xifvCDH2Tw4MG56KKL8g//8A9J/u/nGV544YXMnDmzUN/S0pJt27Zl9erV6dOnz77fJMC7pGcC9EwAu6ZnAvRM7E+CP9iBrl27tvrcvn37tLS0tBrbsmVL4e/tv708d+7c/N3f/V2rupKSkn20SmBf6tq1a4477rjC5//8z//MBRdckKuuuir/9m//lh49emTJkiUZNWpUNm/evMOG7Prrr8/nPve5zJ07Nz/72c9y3XXX5cEHH8ynPvWpvPHGG/mnf/qnfPnLX37b94455ph9ujeAvUXPBOiZAHZNzwTomdifBH+wG973vvflpZdeajW2YsWKwm8o9+3bNyUlJVmzZo2fW4AiVV9fn23btuXWW29N+/b/94rcH/3oR7v83gc+8IF84AMfyNixY/PZz34206dPz6c+9amcdtppefnll1s1fQAHOz0ToGcC2DU9E6BnYl9q39YLgIPBueeem+eeey4PPPBAXnvttVx33XWtGrRu3brlX/7lXzJ27Njcf//9+e1vf5vnn38+d911V+6///42XDmwtxx33HHZsmVL7rrrrvzud7/LD37wg0ybNm2n9X/5y19SW1ubJ598Mv/1X/+Vp556Ks8++2zhpxW++tWvZunSpamtrc2KFSvy2muv5dFHH/XSZeCgpmcC9EwAu6ZnAvRM7EuCP9gN1dXV+frXv55rr702p59+ev70pz/l0ksvbVVz44035utf/3rq6urSp0+fnH/++Zk7d24qKyvbaNXA3tSvX7/cdttt+eY3v5kTTzwxM2fOTF1d3U7rO3TokP/93//NpZdemg984AP59Kc/naFDh+aGG25Ikpx88slZtGhRfv3rX+ess87KqaeemokTJ6ZXr177a0sAe52eCdAzAeyangnQM7EvtWv56x+UBgAAAAAAAA46nvgDAAAAAACAIiD4AwAAAAAAgCIg+AMAAAAAAIAiIPgDAAAAAACAIiD4AwAAAAAAgCIg+AMAAAAAAIAiIPgDAAAAAACAIiD4AwAAAAAAgCIg+AMAAAAAAIAiIPgDAAAAAACAIiD4AwAAAAAAgCIg+AMAAAAAAIAi8P8ASuSHOkK1wtQAAAAASUVORK5CYII=\n"},"metadata":{}}]},{"cell_type":"code","source":["# Process the datasets to generate prompts\n","train_dataset = train_dataset.map(\n","    formatting_prompts_func,\n","    batched=True,\n","    batch_size=64,\n","    num_proc=4,\n","    load_from_cache_file=False,\n",")\n","\n","val_dataset = val_dataset.map(\n","    formatting_prompts_func,\n","    batched=True,\n","    batch_size=64,\n","    num_proc=4,\n","    load_from_cache_file=False,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["d502384275c44013894d52841373a77b","df67f24c3a9d4bea82d36a1888ba47b3","e58da92ff96d4ee78e5f8e609ca14caf","28e0f42597ba47a6ba4bbbe3cbd546eb","f5466c80e4dc405b85ac4179690d47d2","8453491542804fdb8bee25caca77b8b2","fe5ddb391d804389b866889deb7b77fc","848e43d0ec5b4383bf050c086bd6e321","e6631100521f49ab829d3464be9fa745","20389b112a2d4132b0f2c51ff5508201","289647a021894a7dbfaeb79e82b753ed","1421c2d0a3a74cd1a9b9b7e2ab7a5f3a","556b05f1ce3e4de5a3b816bd279dc1c3","fb9a37bcaeee49c0b6d1070ae6d27dd2","2eee1b871dd64dffb32959907450ad11","f34cfe95f3314880a97e91258f4f767b","fe418b487c5d475c862f7789b7bedbb8","ce103984d5ab44fea737e82259e88991","acd4dfc744ae423dbbe3f99eff9a01a8","45ae0f9275174bf78b084475b1f1a400","8f9efff2a3884856a7444edd4ec21e67","fd3fbbe027824419b491568118d248de"]},"id":"tN_hPv-7GSe7","executionInfo":{"status":"ok","timestamp":1731698602700,"user_tz":300,"elapsed":1444,"user":{"displayName":"DeepLearning","userId":"07574442120191513945"}},"outputId":"9a17fac7-7125-4d9d-9ce1-5e4b55c5da21"},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map (num_proc=4):   0%|          | 0/10240 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d502384275c44013894d52841373a77b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map (num_proc=4):   0%|          | 0/2560 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1421c2d0a3a74cd1a9b9b7e2ab7a5f3a"}},"metadata":{}}]},{"cell_type":"markdown","source":["## SFT"],"metadata":{"id":"egSQOrCJeM7n"}},{"cell_type":"code","source":["# # Free up memory before training\n","# torch.cuda.empty_cache()\n","# gc.collect()\n","\n","# # Enable expandable segments (optional, as already in the original code)\n","# os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n"],"metadata":{"id":"5hP-XPCk5G6b","executionInfo":{"status":"ok","timestamp":1731698602700,"user_tz":300,"elapsed":4,"user":{"displayName":"DeepLearning","userId":"07574442120191513945"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["from trl import SFTTrainer\n","from transformers import TrainingArguments\n","from unsloth import is_bfloat16_supported\n","from transformers import Trainer, TrainingArguments, EarlyStoppingCallback\n","\n","torch.cuda.empty_cache()\n","# 与训练有关的重要参数都在这边调\n","# small_train_dataset = train_dataset.select(range(10000))  # 取数据集的一个小样本例如使用前10000个样本\n","trainer = SFTTrainer(\n","    model = model,\n","    tokenizer = tokenizer,\n","    train_dataset = train_dataset,\n","    # eval_dataset = val_dataset,\n","    dataset_text_field = \"text\",\n","    max_seq_length = max_seq_length,\n","    dataset_num_proc = 4,\n","    packing = False, # Can make training 5x faster for short sequences.\n","    args = TrainingArguments(\n","        per_device_train_batch_size = 16,\n","        per_device_eval_batch_size=16,\n","        gradient_accumulation_steps = 4,\n","        warmup_steps = 10,\n","        num_train_epochs = 10, # Set this for 1 full training run.\n","        max_steps = 160,\n","        learning_rate = 2e-4, #changed from 2e-4, continue training based on /content/lr2e-4_step500_lora\n","        fp16 = not is_bfloat16_supported(),\n","        bf16 = is_bfloat16_supported(),\n","        logging_steps = 1,\n","        optim = \"adamw_8bit\",\n","        weight_decay = 0.01,\n","        lr_scheduler_type = \"linear\",\n","        seed = 3407,\n","        output_dir = \"outputs\",\n","        report_to = \"none\", # Use this for WandB etc\n","        # Evaluation settings\n","        # evaluation_strategy=\"steps\",\n","        # eval_steps=10,\n","        # save_strategy=\"steps\",\n","        # save_steps=10,\n","        # load_best_model_at_end=True,\n","        # metric_for_best_model=\"eval_loss\",\n","    )\n",")\n","\n","# from transformers import TrainerCallback\n","\n","# class EvalLoggingCallback(TrainerCallback):\n","#     def on_evaluate(self, args, state, control, metrics=None, **kwargs):\n","#         if metrics and \"eval_loss\" in metrics:\n","#             print(f\"Evaluation loss at step {state.global_step}: {metrics['eval_loss']}\")\n","\n","# trainer.add_callback(EvalLoggingCallback)\n"],"metadata":{"id":"E_baCfhcWw4v","colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["a229d990f9dc4f0f86ec81a40543f671","f8000c19d2724b80b84cce7fd0fce43c","47e6312cfa624311b8b89f0558f7360c","c194e2f6cde042ffadeaa42d3e6be881","6df548f3f8194bb8be5362d16b5009f4","d8946b14e70a4bed93b8c821099cb2da","4b157e000c534486a7adbdeb0b44c1bc","c355a5ce39644ff38d3505c1b1b3de93","e9468bd86cce4bd7b0e26b980779ce4b","f340fa4675ad4d59bf5089d2d46ed7dc","a0c5547f71f441cb8b4f078e35fb569e"]},"executionInfo":{"status":"ok","timestamp":1731698607906,"user_tz":300,"elapsed":5209,"user":{"displayName":"DeepLearning","userId":"07574442120191513945"}},"outputId":"4fa4d767-76eb-48fa-f0b3-5f4c80001849"},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map (num_proc=4):   0%|          | 0/10240 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a229d990f9dc4f0f86ec81a40543f671"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["max_steps is given, it will override any value given in num_train_epochs\n"]}]},{"cell_type":"code","source":["# del inputs\n","# del outputs\n","# del trainer_stats\n","# del tokenizer\n","# del model\n","# torch.cuda.empty_cache()\n","# gc.collect()"],"metadata":{"id":"QDmWAZoQ1dzJ","executionInfo":{"status":"ok","timestamp":1731698607906,"user_tz":300,"elapsed":4,"user":{"displayName":"DeepLearning","userId":"07574442120191513945"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["print(\"Evaluation dataset size:\", len(val_dataset))\n","print(\"Evaluation dataset size:\", len(train_dataset))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_YlvGPPeSs74","executionInfo":{"status":"ok","timestamp":1731698607907,"user_tz":300,"elapsed":4,"user":{"displayName":"DeepLearning","userId":"07574442120191513945"}},"outputId":"6862fdb7-f2d2-4a69-a939-17779c443856"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Evaluation dataset size: 2560\n","Evaluation dataset size: 10240\n"]}]},{"cell_type":"code","source":["# del inputs\n","# del outputs"],"metadata":{"id":"3LzZ4Bg_qfl9","executionInfo":{"status":"ok","timestamp":1731698607907,"user_tz":300,"elapsed":3,"user":{"displayName":"DeepLearning","userId":"07574442120191513945"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["PYTORCH_CUDA_ALLOC_CONF=expandable_segments=True\n","torch.cuda.empty_cache()\n","trainer_stats = trainer.train()"],"metadata":{"id":"WquBPTm4b-3z","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1731700609509,"user_tz":300,"elapsed":2001605,"user":{"displayName":"DeepLearning","userId":"07574442120191513945"}},"outputId":"0686f798-d84b-4eaf-c246-58f44f8a84e1"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stderr","text":["==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n","   \\\\   /|    Num examples = 10,240 | Num Epochs = 1\n","O^O/ \\_/ \\    Batch size per device = 16 | Gradient Accumulation steps = 4\n","\\        /    Total batch size = 64 | Total steps = 160\n"," \"-____-\"     Number of trainable parameters = 41,943,040\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='160' max='160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [160/160 33:00, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.315800</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.316100</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.338500</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.320700</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.367500</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.370900</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.341900</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.349800</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.347700</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.318700</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>0.387300</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>0.354900</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>0.393400</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>0.361200</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>0.385400</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>0.366200</td>\n","    </tr>\n","    <tr>\n","      <td>17</td>\n","      <td>0.358200</td>\n","    </tr>\n","    <tr>\n","      <td>18</td>\n","      <td>0.380000</td>\n","    </tr>\n","    <tr>\n","      <td>19</td>\n","      <td>0.375000</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.380500</td>\n","    </tr>\n","    <tr>\n","      <td>21</td>\n","      <td>0.373300</td>\n","    </tr>\n","    <tr>\n","      <td>22</td>\n","      <td>0.371500</td>\n","    </tr>\n","    <tr>\n","      <td>23</td>\n","      <td>0.333200</td>\n","    </tr>\n","    <tr>\n","      <td>24</td>\n","      <td>0.353900</td>\n","    </tr>\n","    <tr>\n","      <td>25</td>\n","      <td>0.375700</td>\n","    </tr>\n","    <tr>\n","      <td>26</td>\n","      <td>0.364100</td>\n","    </tr>\n","    <tr>\n","      <td>27</td>\n","      <td>0.394100</td>\n","    </tr>\n","    <tr>\n","      <td>28</td>\n","      <td>0.364500</td>\n","    </tr>\n","    <tr>\n","      <td>29</td>\n","      <td>0.408700</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.381700</td>\n","    </tr>\n","    <tr>\n","      <td>31</td>\n","      <td>0.410700</td>\n","    </tr>\n","    <tr>\n","      <td>32</td>\n","      <td>0.379700</td>\n","    </tr>\n","    <tr>\n","      <td>33</td>\n","      <td>0.327800</td>\n","    </tr>\n","    <tr>\n","      <td>34</td>\n","      <td>0.382600</td>\n","    </tr>\n","    <tr>\n","      <td>35</td>\n","      <td>0.426700</td>\n","    </tr>\n","    <tr>\n","      <td>36</td>\n","      <td>0.390300</td>\n","    </tr>\n","    <tr>\n","      <td>37</td>\n","      <td>0.357300</td>\n","    </tr>\n","    <tr>\n","      <td>38</td>\n","      <td>0.400400</td>\n","    </tr>\n","    <tr>\n","      <td>39</td>\n","      <td>0.376300</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.360300</td>\n","    </tr>\n","    <tr>\n","      <td>41</td>\n","      <td>0.348300</td>\n","    </tr>\n","    <tr>\n","      <td>42</td>\n","      <td>0.355200</td>\n","    </tr>\n","    <tr>\n","      <td>43</td>\n","      <td>0.382900</td>\n","    </tr>\n","    <tr>\n","      <td>44</td>\n","      <td>0.327600</td>\n","    </tr>\n","    <tr>\n","      <td>45</td>\n","      <td>0.323300</td>\n","    </tr>\n","    <tr>\n","      <td>46</td>\n","      <td>0.362300</td>\n","    </tr>\n","    <tr>\n","      <td>47</td>\n","      <td>0.356000</td>\n","    </tr>\n","    <tr>\n","      <td>48</td>\n","      <td>0.373800</td>\n","    </tr>\n","    <tr>\n","      <td>49</td>\n","      <td>0.367100</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.319700</td>\n","    </tr>\n","    <tr>\n","      <td>51</td>\n","      <td>0.360200</td>\n","    </tr>\n","    <tr>\n","      <td>52</td>\n","      <td>0.361500</td>\n","    </tr>\n","    <tr>\n","      <td>53</td>\n","      <td>0.355700</td>\n","    </tr>\n","    <tr>\n","      <td>54</td>\n","      <td>0.370200</td>\n","    </tr>\n","    <tr>\n","      <td>55</td>\n","      <td>0.359400</td>\n","    </tr>\n","    <tr>\n","      <td>56</td>\n","      <td>0.360900</td>\n","    </tr>\n","    <tr>\n","      <td>57</td>\n","      <td>0.350600</td>\n","    </tr>\n","    <tr>\n","      <td>58</td>\n","      <td>0.350200</td>\n","    </tr>\n","    <tr>\n","      <td>59</td>\n","      <td>0.371700</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.334000</td>\n","    </tr>\n","    <tr>\n","      <td>61</td>\n","      <td>0.341700</td>\n","    </tr>\n","    <tr>\n","      <td>62</td>\n","      <td>0.397000</td>\n","    </tr>\n","    <tr>\n","      <td>63</td>\n","      <td>0.372900</td>\n","    </tr>\n","    <tr>\n","      <td>64</td>\n","      <td>0.345800</td>\n","    </tr>\n","    <tr>\n","      <td>65</td>\n","      <td>0.387700</td>\n","    </tr>\n","    <tr>\n","      <td>66</td>\n","      <td>0.368400</td>\n","    </tr>\n","    <tr>\n","      <td>67</td>\n","      <td>0.381300</td>\n","    </tr>\n","    <tr>\n","      <td>68</td>\n","      <td>0.363500</td>\n","    </tr>\n","    <tr>\n","      <td>69</td>\n","      <td>0.356500</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.352000</td>\n","    </tr>\n","    <tr>\n","      <td>71</td>\n","      <td>0.336100</td>\n","    </tr>\n","    <tr>\n","      <td>72</td>\n","      <td>0.358900</td>\n","    </tr>\n","    <tr>\n","      <td>73</td>\n","      <td>0.388300</td>\n","    </tr>\n","    <tr>\n","      <td>74</td>\n","      <td>0.345600</td>\n","    </tr>\n","    <tr>\n","      <td>75</td>\n","      <td>0.355800</td>\n","    </tr>\n","    <tr>\n","      <td>76</td>\n","      <td>0.354200</td>\n","    </tr>\n","    <tr>\n","      <td>77</td>\n","      <td>0.355900</td>\n","    </tr>\n","    <tr>\n","      <td>78</td>\n","      <td>0.393800</td>\n","    </tr>\n","    <tr>\n","      <td>79</td>\n","      <td>0.357200</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.330500</td>\n","    </tr>\n","    <tr>\n","      <td>81</td>\n","      <td>0.417400</td>\n","    </tr>\n","    <tr>\n","      <td>82</td>\n","      <td>0.353000</td>\n","    </tr>\n","    <tr>\n","      <td>83</td>\n","      <td>0.359200</td>\n","    </tr>\n","    <tr>\n","      <td>84</td>\n","      <td>0.375300</td>\n","    </tr>\n","    <tr>\n","      <td>85</td>\n","      <td>0.375500</td>\n","    </tr>\n","    <tr>\n","      <td>86</td>\n","      <td>0.390700</td>\n","    </tr>\n","    <tr>\n","      <td>87</td>\n","      <td>0.319500</td>\n","    </tr>\n","    <tr>\n","      <td>88</td>\n","      <td>0.349700</td>\n","    </tr>\n","    <tr>\n","      <td>89</td>\n","      <td>0.375000</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.339400</td>\n","    </tr>\n","    <tr>\n","      <td>91</td>\n","      <td>0.341500</td>\n","    </tr>\n","    <tr>\n","      <td>92</td>\n","      <td>0.343800</td>\n","    </tr>\n","    <tr>\n","      <td>93</td>\n","      <td>0.374100</td>\n","    </tr>\n","    <tr>\n","      <td>94</td>\n","      <td>0.314500</td>\n","    </tr>\n","    <tr>\n","      <td>95</td>\n","      <td>0.352800</td>\n","    </tr>\n","    <tr>\n","      <td>96</td>\n","      <td>0.395800</td>\n","    </tr>\n","    <tr>\n","      <td>97</td>\n","      <td>0.351900</td>\n","    </tr>\n","    <tr>\n","      <td>98</td>\n","      <td>0.387700</td>\n","    </tr>\n","    <tr>\n","      <td>99</td>\n","      <td>0.340700</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.345500</td>\n","    </tr>\n","    <tr>\n","      <td>101</td>\n","      <td>0.347400</td>\n","    </tr>\n","    <tr>\n","      <td>102</td>\n","      <td>0.340500</td>\n","    </tr>\n","    <tr>\n","      <td>103</td>\n","      <td>0.360000</td>\n","    </tr>\n","    <tr>\n","      <td>104</td>\n","      <td>0.357100</td>\n","    </tr>\n","    <tr>\n","      <td>105</td>\n","      <td>0.406500</td>\n","    </tr>\n","    <tr>\n","      <td>106</td>\n","      <td>0.349700</td>\n","    </tr>\n","    <tr>\n","      <td>107</td>\n","      <td>0.350500</td>\n","    </tr>\n","    <tr>\n","      <td>108</td>\n","      <td>0.366600</td>\n","    </tr>\n","    <tr>\n","      <td>109</td>\n","      <td>0.342400</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.368400</td>\n","    </tr>\n","    <tr>\n","      <td>111</td>\n","      <td>0.350500</td>\n","    </tr>\n","    <tr>\n","      <td>112</td>\n","      <td>0.336900</td>\n","    </tr>\n","    <tr>\n","      <td>113</td>\n","      <td>0.339300</td>\n","    </tr>\n","    <tr>\n","      <td>114</td>\n","      <td>0.350400</td>\n","    </tr>\n","    <tr>\n","      <td>115</td>\n","      <td>0.350400</td>\n","    </tr>\n","    <tr>\n","      <td>116</td>\n","      <td>0.348800</td>\n","    </tr>\n","    <tr>\n","      <td>117</td>\n","      <td>0.340400</td>\n","    </tr>\n","    <tr>\n","      <td>118</td>\n","      <td>0.394400</td>\n","    </tr>\n","    <tr>\n","      <td>119</td>\n","      <td>0.370700</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.323400</td>\n","    </tr>\n","    <tr>\n","      <td>121</td>\n","      <td>0.349200</td>\n","    </tr>\n","    <tr>\n","      <td>122</td>\n","      <td>0.336800</td>\n","    </tr>\n","    <tr>\n","      <td>123</td>\n","      <td>0.315100</td>\n","    </tr>\n","    <tr>\n","      <td>124</td>\n","      <td>0.370900</td>\n","    </tr>\n","    <tr>\n","      <td>125</td>\n","      <td>0.342100</td>\n","    </tr>\n","    <tr>\n","      <td>126</td>\n","      <td>0.363000</td>\n","    </tr>\n","    <tr>\n","      <td>127</td>\n","      <td>0.351800</td>\n","    </tr>\n","    <tr>\n","      <td>128</td>\n","      <td>0.357200</td>\n","    </tr>\n","    <tr>\n","      <td>129</td>\n","      <td>0.335200</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.329000</td>\n","    </tr>\n","    <tr>\n","      <td>131</td>\n","      <td>0.332700</td>\n","    </tr>\n","    <tr>\n","      <td>132</td>\n","      <td>0.343600</td>\n","    </tr>\n","    <tr>\n","      <td>133</td>\n","      <td>0.350600</td>\n","    </tr>\n","    <tr>\n","      <td>134</td>\n","      <td>0.378600</td>\n","    </tr>\n","    <tr>\n","      <td>135</td>\n","      <td>0.350000</td>\n","    </tr>\n","    <tr>\n","      <td>136</td>\n","      <td>0.445900</td>\n","    </tr>\n","    <tr>\n","      <td>137</td>\n","      <td>0.363200</td>\n","    </tr>\n","    <tr>\n","      <td>138</td>\n","      <td>0.361300</td>\n","    </tr>\n","    <tr>\n","      <td>139</td>\n","      <td>0.406400</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.381900</td>\n","    </tr>\n","    <tr>\n","      <td>141</td>\n","      <td>0.351500</td>\n","    </tr>\n","    <tr>\n","      <td>142</td>\n","      <td>0.340200</td>\n","    </tr>\n","    <tr>\n","      <td>143</td>\n","      <td>0.342000</td>\n","    </tr>\n","    <tr>\n","      <td>144</td>\n","      <td>0.305700</td>\n","    </tr>\n","    <tr>\n","      <td>145</td>\n","      <td>0.362800</td>\n","    </tr>\n","    <tr>\n","      <td>146</td>\n","      <td>0.315500</td>\n","    </tr>\n","    <tr>\n","      <td>147</td>\n","      <td>0.351300</td>\n","    </tr>\n","    <tr>\n","      <td>148</td>\n","      <td>0.319900</td>\n","    </tr>\n","    <tr>\n","      <td>149</td>\n","      <td>0.322900</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.394300</td>\n","    </tr>\n","    <tr>\n","      <td>151</td>\n","      <td>0.335100</td>\n","    </tr>\n","    <tr>\n","      <td>152</td>\n","      <td>0.327100</td>\n","    </tr>\n","    <tr>\n","      <td>153</td>\n","      <td>0.320000</td>\n","    </tr>\n","    <tr>\n","      <td>154</td>\n","      <td>0.372400</td>\n","    </tr>\n","    <tr>\n","      <td>155</td>\n","      <td>0.347200</td>\n","    </tr>\n","    <tr>\n","      <td>156</td>\n","      <td>0.341000</td>\n","    </tr>\n","    <tr>\n","      <td>157</td>\n","      <td>0.334500</td>\n","    </tr>\n","    <tr>\n","      <td>158</td>\n","      <td>0.311300</td>\n","    </tr>\n","    <tr>\n","      <td>159</td>\n","      <td>0.349200</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.365800</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}}]},{"cell_type":"markdown","source":["## Saving model"],"metadata":{"id":"pKt3vZoSeRvb"}},{"cell_type":"code","source":["model.save_pretrained(\"lora_model\") # Local saving\n","tokenizer.save_pretrained(\"lora_model\")"],"metadata":{"id":"VRiW2RQ0cWru","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1731700610862,"user_tz":300,"elapsed":1357,"user":{"displayName":"DeepLearning","userId":"07574442120191513945"}},"outputId":"1b2d90ed-7027-4fda-9bb5-1906add97e19"},"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('lora_model/tokenizer_config.json',\n"," 'lora_model/special_tokens_map.json',\n"," 'lora_model/tokenizer.json')"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["# Sample inferene data point\n","test_dataset = full_dataset['test']\n","sample_ques = test_dataset['question'][0]\n","sample_sols = test_dataset['solution'][0]\n","sample_ans = test_dataset['answer'][0]"],"metadata":{"id":"PKonoiHFCPeE","executionInfo":{"status":"ok","timestamp":1731700610862,"user_tz":300,"elapsed":3,"user":{"displayName":"DeepLearning","userId":"07574442120191513945"}}},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":["## Calculate accuracy on validation dataset\n"],"metadata":{"id":"gACDHronXTWz"}},{"cell_type":"code","source":["# Function to validate on validation dataset\n","def validate_model(model, tokenizer, val_dataset):\n","    predictions = []\n","    actual = []\n","\n","    for i in range(len(val_dataset)):\n","        input_prompt = prompt.format(\n","            val_dataset['question'][i],\n","            val_dataset['answer'][i],\n","            val_dataset['solution'][i],\n","            \"\"\n","        )\n","\n","        inputs = tokenizer([input_prompt], return_tensors=\"pt\").to(\"cuda\")\n","        outputs = model.generate(**inputs, max_new_tokens=64, use_cache=True, top_p=0.9)\n","        response = tokenizer.decode(outputs[0][len(inputs['input_ids'][0]):], skip_special_tokens=True)\n","\n","        prediction = True if 'True' in response.split()[0] else False\n","        predictions.append(prediction)\n","        actual.append(val_dataset['is_correct'][i])\n","\n","        if i % 100 == 0:\n","            torch.cuda.empty_cache()\n","            print(f\"Processed {i}/{len(val_dataset)} samples\")\n","\n","    # Calculate accuracy\n","    accuracy = sum(p == a for p, a in zip(predictions, actual)) / len(predictions)\n","    print(f\"\\nValidation Accuracy: {accuracy:.4f}\")\n","\n","    # Save predictions\n","    # val_results = pd.DataFrame({\n","    #     'predicted': predictions,\n","    #     'actual': actual\n","    # })\n","    # val_results.to_csv('validation_results.csv', index=False)\n","    del inputs, outputs\n","    return accuracy\n","\n","# Run validation after training\n","FastLanguageModel.for_inference(model)\n","accuracy = validate_model(model, tokenizer, val_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":436},"id":"gOhnPoEbX8kt","executionInfo":{"status":"error","timestamp":1731700626371,"user_tz":300,"elapsed":3850,"user":{"displayName":"DeepLearning","userId":"07574442120191513945"}},"outputId":"92a75130-6d1f-49e0-af6f-53f669ac2dea"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["Processed 0/2560 samples\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-33-737bef2239cd>\u001b[0m in \u001b[0;36m<cell line: 41>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# Run validation after training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mFastLanguageModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-33-737bef2239cd>\u001b[0m in \u001b[0;36mvalidate_model\u001b[0;34m(model, tokenizer, val_dataset)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_prompt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_p\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36m_fast_generate\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1422\u001b[0m         \u001b[0;31m# Autocasted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1423\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1424\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1425\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/peft/peft_model.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1702\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_peft_forward_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1703\u001b[0m                     \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial_peft_forward_args\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1704\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1705\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1706\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2214\u001b[0m             \u001b[0;31m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2215\u001b[0;31m             result = self._sample(\n\u001b[0m\u001b[1;32m   2216\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2217\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepared_logits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0;31m# forward pass to get next token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m             \u001b[0;31m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36m_CausalLM_fast_forward\u001b[0;34m(self, input_ids, causal_mask, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, num_logits_to_keep, *args, **kwargs)\u001b[0m\n\u001b[1;32m    924\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpast_key_values\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m             outputs = fast_forward_inference(\n\u001b[0m\u001b[1;32m    927\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36mLlamaModel_fast_forward_inference\u001b[0;34m(self, input_ids, past_key_values, position_ids, attention_mask)\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfast_rms_layernorm_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_attention_layernorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfast_swiglu_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mresidual\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36mfast_swiglu_inference\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0;31m# temp = torch.empty((2, bsz, 1, mlp_size), dtype = X.dtype, device = \"cuda:0\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m     \u001b[0mgate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfast_linear_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgate_proj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, out = temp[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m     \u001b[0mup\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mfast_linear_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mup_proj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, out = temp[1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0mgate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch_nn_functional_silu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/unsloth/kernels/utils.py\u001b[0m in \u001b[0;36mfast_linear_forward\u001b[0;34m(proj, X, temp_lora, out)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbsz\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m             \u001b[0mtemp_lora\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlora_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fast_lora\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_lora\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlora_B\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fast_lora\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_lora\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlora_S\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["## inference"],"metadata":{"id":"OjOqIXhCePfQ"}},{"cell_type":"code","source":["# del outputs\n","# del tokenizer\n","# del trainer\n","# del trainer_stats"],"metadata":{"id":"xlcOKk0m-DQj","executionInfo":{"status":"ok","timestamp":1731700631490,"user_tz":300,"elapsed":1043,"user":{"displayName":"DeepLearning","userId":"07574442120191513945"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["torch.cuda.empty_cache()\n","if True:\n","    from unsloth import FastLanguageModel\n","    model, tokenizer = FastLanguageModel.from_pretrained(\n","        model_name = \"lora_model\", # YOUR MODEL YOU USED FOR TRAINING\n","        max_seq_length = max_seq_length,\n","        dtype = dtype,\n","        load_in_4bit = load_in_4bit,\n","        # llm_int8_enable_fp32_cpu_offload=True\n","    )\n","    FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n"],"metadata":{"id":"paHfJLfVccmN","colab":{"base_uri":"https://localhost:8080/","height":176,"referenced_widgets":["9924dbd6d95549e4ab83e6a4c7948173","57abab8317584ebeac65cb9fe8788bc9","42254a9e8c6e4f08b1e7711517ef5838","e5f8486b23644da386b069ddcb8e7b9e","0403a0513dce444291a12e1dbe56deee","76bf7d40ea7543e4b4b75c6e53cf9871","c18709838bc34062bc621dcaadfa27fa","58e5d914a4dd492cb43dfbbf50cc3eb7","1c3c43ff287a42bcb8d47b5d73b47fcc","96c81791bc7247149af19fac1841c78e","561d3c1665914c6a9ed6538199da111f"]},"executionInfo":{"status":"ok","timestamp":1731700650475,"user_tz":300,"elapsed":17094,"user":{"displayName":"DeepLearning","userId":"07574442120191513945"}},"outputId":"aa4b2bc8-6c6f-44fd-ac9c-e199b282cb88"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["==((====))==  Unsloth 2024.11.7: Fast Llama patching. Transformers = 4.46.2.\n","   \\\\   /|    GPU: NVIDIA A100-SXM4-40GB. Max memory: 39.564 GB. Platform = Linux.\n","O^O/ \\_/ \\    Pytorch: 2.5.1+cu124. CUDA = 8.0. CUDA Toolkit = 12.4.\n","\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post3. FA2 = False]\n"," \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"]},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9924dbd6d95549e4ab83e6a4c7948173"}},"metadata":{}}]},{"cell_type":"code","source":["# Running inference on single test\n","FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n","input_prompt = prompt.format(\n","        sample_ques, # ques\n","        sample_ans, # given answer\n","        sample_sols, # solution\n","        \"\", # output - leave this blank for generation! LLM willl generate is it is True or False\n","    )\n","\n","print(\"Input Promt:\\n\", input_prompt)\n","inputs = tokenizer(\n","[\n","    input_prompt\n","], return_tensors = \"pt\").to(\"cuda\")\n","\n","input_shape = inputs['input_ids'].shape\n","input_token_len = input_shape[1] # 1 because of batch\n","outputs = model.generate(**inputs, max_new_tokens = 64, use_cache = True, top_p=0.9).to(\"cuda\")\n","# you can get the whole generated text by uncommenting the below line\n","# text_generated = tokenizer.batch_decode([outputs, skip_special_tokens=True)\n","\n","response = tokenizer.batch_decode([outputs[0][input_token_len:]], skip_special_tokens=True)\n","response"],"metadata":{"id":"RNqkb-2-cAyA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1731700653247,"user_tz":300,"elapsed":1003,"user":{"displayName":"DeepLearning","userId":"07574442120191513945"}},"outputId":"cfc9a376-d63d-495b-ef54-8beda9ae1219"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["Input Promt:\n"," You are a great mathematician and you are tasked with finding if an answer to a given maths question is correct or not.\n","Follow these steps to verify if the given answer is correct.\n","\n","### [Step 1] Task Description\n","Carefully read the question to understand the type of mathematical problem.\n","Question:\n","The Parker family needs to leave the house by 5 pm for a dinner party. Mrs. Parker was waiting to get into the bathroom at 2:30 pm. Her oldest daughter used the bathroom for 45 minutes and her youngest daughter used the bathroom for another 30 minutes. Then her husband used it for 20 minutes. How much time will Mrs. Parker have to use the bathroom to leave on time?\n","\n","### [Step 2]Check the given answer\n","Examine the provided answer below to determine if it is mathematically equivalent to the computed solution.\n","Given Answer:\n","205\n","\n","### [Step 3] Verify and solve step by step\n","- Check if all given information is used correctly\n","- Verify calculations and mathematical operations\n","Step-by-step verification:\n","Let's solve this problem using Python code.\n","<llm-code>\n","minutes_per_hour = 60\n","minutes_left_before_5 = 5 * minutes_per_hour\n","total_time_spent_by_family = 45 + 30 + 20\n","minutes_before_5_after_family = minutes_left_before_5 - total_time_spent_by_family\n","minutes_before_5_after_family\n","</llm-code>\n","<llm-code-output>\n","205\n","</llm-code-output>\n","Thus Mrs. Parker will have \\boxed{205} minutes in the bathroom before the family leaves.\n","\n","###[Step 4] After completing the verification steps, respond ONLY with \"True\" if correct, or \"False\" if it is not.\n","Output:\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["['False']"]},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":[],"metadata":{"id":"5_P66lcbXSik","executionInfo":{"status":"aborted","timestamp":1731700620726,"user_tz":300,"elapsed":10,"user":{"displayName":"DeepLearning","userId":"07574442120191513945"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"g2yjoizFXg-6","executionInfo":{"status":"aborted","timestamp":1731700620726,"user_tz":300,"elapsed":10,"user":{"displayName":"DeepLearning","userId":"07574442120191513945"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Create submittion csv on test dataset"],"metadata":{"id":"yK6_euuHXcb4"}},{"cell_type":"code","source":["!pip install tqdm pandas\n","\n","import os\n","import torch\n","from tqdm import tqdm\n","import pandas as pd\n","os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'"],"metadata":{"id":"xDbMAuD9xZY-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1731700662362,"user_tz":300,"elapsed":3009,"user":{"displayName":"DeepLearning","userId":"07574442120191513945"}},"outputId":"e9089cc6-bcbc-456e-971d-59e779c64193"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.6)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n","Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"]}]},{"cell_type":"code","source":["def create_submission(model, tokenizer, test_dataset, batch_size=4):\n","    FastLanguageModel.for_inference(model)\n","    predictions = []\n","\n","    # Process test dataset in batches with progress bar\n","    for i in tqdm(range(0, len(test_dataset), batch_size), desc=\"Processing test dataset\"):\n","        # Clear cache periodically\n","        if i % 100 == 0:\n","            torch.cuda.empty_cache()\n","\n","        batch_end = min(i + batch_size, len(test_dataset))\n","        batch_questions = test_dataset['question'][i:batch_end]\n","        batch_solutions = test_dataset['solution'][i:batch_end]\n","        batch_answers = test_dataset['answer'][i:batch_end]\n","\n","        # Create prompts for the batch\n","        batch_prompts = [\n","            prompt.format(q, a, s,\"\")\n","            for q, s, a in zip(batch_questions,batch_solutions,batch_answers)\n","        ]\n","\n","        try:\n","            # Tokenize batch\n","            inputs = tokenizer(\n","                batch_prompts,\n","                return_tensors=\"pt\",\n","                padding=True,\n","                truncation=True,\n","                max_length=512\n","            ).to(\"cuda\")\n","\n","            # Generate predictions\n","            with torch.inference_mode():\n","                outputs = model.generate(\n","                    **inputs,\n","                    max_new_tokens=64,\n","                    top_p=0.9,\n","                    use_cache=True,\n","                    pad_token_id=tokenizer.eos_token_id\n","                )\n","\n","            # Process outputs\n","            for j in range(len(outputs)):\n","                input_len = len(inputs['input_ids'][j])\n","                response = tokenizer.decode(outputs[j][input_len:], skip_special_tokens=True).strip()\n","                prediction = True if 'True' in response.split()[0] else False\n","                predictions.append(prediction)\n","\n","            # Clean up\n","            del inputs, outputs\n","\n","        except RuntimeError as e:\n","            print(f\"\\nError in batch processing at index {i}. Switching to single example processing.\")\n","            # Process examples one by one if batch fails\n","            for q, a,s in zip(batch_questions, batch_answers,batch_solutions):\n","                try:\n","                    single_prompt = prompt.format(q, a, s,\"\")\n","                    inputs = tokenizer([single_prompt], return_tensors=\"pt\", truncation=True, max_length=512)\n","                    with torch.inference_mode():\n","                        outputs = model.generate(**inputs, max_new_tokens=64, top_p=0.9, use_cache=True)\n","                    response = tokenizer.decode(outputs[0][len(inputs['input_ids'][0]):], skip_special_tokens=True).strip()\n","                    prediction = True if 'True' in response.split()[0] else False\n","                    predictions.append(prediction)\n","                    del inputs, outputs\n","                    torch.cuda.empty_cache()\n","                except Exception as e:\n","                    print(f\"\\nError processing single example: {e}\")\n","                    predictions.append(False)  # Default prediction in case of error\n","\n","    # Create final submission DataFrame\n","    submission_df = pd.DataFrame({\n","        'ID': range(len(predictions)),\n","        'is_correct': predictions\n","    })\n","\n","    if len(submission_df) != len(test_dataset):\n","        print(f\"\\nWarning: Number of predictions ({len(predictions)}) doesn't match test dataset size ({len(test_dataset)})\")\n","\n","    # Save submission\n","    submission_df.to_csv('submission.csv', index=False)\n","    print(\"\\nSubmission saved successfully!\")\n","    print(f\"Total predictions: {len(predictions)}\")\n","    print(\"\\nFirst few predictions:\")\n","    print(submission_df.head())\n","\n","    return submission_df\n","\n","# Clear GPU memory before running\n","print(\"Clearing GPU memory...\")\n","torch.cuda.empty_cache()\n","\n","# Create submission\n","test_dataset = full_dataset['test']\n","submission = create_submission(\n","    model=model,\n","    tokenizer=tokenizer,\n","    test_dataset=test_dataset,\n","    batch_size=25\n",")"],"metadata":{"id":"kiiAwjYE08a3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1731702491440,"user_tz":300,"elapsed":1827278,"user":{"displayName":"DeepLearning","userId":"07574442120191513945"}},"outputId":"7287b349-d35f-48b7-c025-0f3a1e872c14"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["Clearing GPU memory...\n"]},{"output_type":"stream","name":"stderr","text":["Processing test dataset: 100%|██████████| 400/400 [30:27<00:00,  4.57s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","Submission saved successfully!\n","Total predictions: 10000\n","\n","First few predictions:\n","   ID  is_correct\n","0   0       False\n","1   1       False\n","2   2       False\n","3   3       False\n","4   4       False\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"R4fSh_Am1FJT","executionInfo":{"status":"aborted","timestamp":1731700620726,"user_tz":300,"elapsed":9,"user":{"displayName":"DeepLearning","userId":"07574442120191513945"}}},"execution_count":null,"outputs":[]}]}